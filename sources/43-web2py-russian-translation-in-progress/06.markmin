## Абстрактный уровень базы данных
``DAL``:inxx

### Зависимости

web2py поставляется с модулем абстрактного уровня базы данных (DAL), который посредством API позволяет отобразить объекты Python в такие объекты базы данных, как запросы, таблицы и записи. DAL динамически генерирует SQL в режиме реального времени, используя указанный диалект для конечной базы данных, так что вам не придется писать код SQL или изучать различные диалекты SQL (термин SQL используется обобщенно), и приложение будет переносимым между различными типами баз данных. Частичный список поддерживаемых баз данных показан в таблице ниже. Пожалуйста, проверьте на веб-сайте web2py и список рассылки для получения более свежих адаптеров. Google NoSQL рассматривается как частный случай в главе 13.

Раздел Gotchas в конце этой главы содержит более подробную информацию о конкретных базах данных.

Бинарный дистрибутив Windows, работает из коробки с SQLite, MySQL, PostgreSQL и MySQL. Бинарный дистрибутив Mac работает из коробки с SQLite.
Чтобы использовать любую другую базу данных со стороны сервера(back-end), из дистрибутива с исходным кодом запустите и установите соответствующий драйвер, требуемый со стороны сервера(back end).
``database drivers``:inxx

После того, как правильный драйвер установлен, запустите web2py из источника, и он найдет драйвер. Вот список драйверов web2py которые можно использовать:

``DAL``:inxx ``SQLite``:inxx ``MySQL``:inxx ``PostgresSQL``:inxx ``Oracle``:inxx ``MSSQL``:inxx ``FireBird``:inxx ``DB2``:inxx ``Informix``:inxx ``Sybase``:inxx ``Teradata``:inxx ``MongoDB``:inxx ``CouchDB``:inxx ``SAPDB``:inxx ``Cubrid``:inxx

----------
database | drivers (source)
SQLite | sqlite3 or pysqlite2 or zxJDBC ``zxjdbc``:cite  (on Jython)
PostgreSQL | psycopg2 ``psycopg2``:cite  or pg8000 ``pg8000``:cite or zxJDBC ``zxjdbc``:cite  (on Jython)
MySQL | pymysql ``pymysql``:cite or MySQLdb ``mysqldb``:cite
Oracle | cx_Oracle ``cxoracle``:cite
MSSQL | pyodbc ``pyodbc``:cite or pypyodbc``pypyodbc``:cite
FireBird | kinterbasdb ``kinterbasdb``:cite or fdb or pyodbc
DB2 | pyodbc ``pyodbc``:cite
Informix | informixdb ``informixdb``:cite
Ingres | ingresdbi ``ingresdbi``:cite
Cubrid | cubriddb ``cubridb``:cite ``cubridb``:cite
Sybase | Sybase ``Sybase``:cite
Teradata | pyodbc ``Teradata``:cite
SAPDB    | sapdb ``SAPDB``:cite
MongoDB | pymongo ``pymongo``:cite
IMAP | imaplib ``IMAP``:cite
---------

``sqlite3``, ``pymysql``, ``pg8000``, и ``imaplib`` идут вместе с web2py. Поддержка MongoDB является экспериментальной. Опция IMAP позволяет использовать DAL для доступа по протоколу IMAP.

### DAL: Быстрый тур
web2py определяет следующие классы, которые составляют DAL:

Объект **DAL** представляет собой соединение с базой данных. Например:
``sqlite``:inxx
``
db = DAL('sqlite://storage.sqlite')
``:code

``define_table``:inxx
Класс таблицы **Table** представляет собой таблицу базы данных. Вы не создаете экземпляр Table  напрямую, за вас это делает ``DAL.define_table``, который и создает экземпляр.
``
db.define_table('mytable', Field('myfield'))
``:code

Наиболее важными методами класса Table являются:
``insert``:inxx
``truncate``:inxx
``drop``:inxx
``import_from_csv_file``:inxx
``count``:inxx
``.insert``, ``.truncate``, ``.drop``, и ``.import_from_csv_file``.

``Field``:inxx
Класс **Field** представляет собой поле базы данных. Вы можете создать экземпляр класса и передать в качестве аргумента при определении таблицы ``DAL.define_table``.

``Rows``:inxx
**DAL Rows** ``Row``:inxx  это объект, возвращаемый методом select базы данных. Это можно представить в виде списка строк ``Row``:
``
rows = db(db.mytable.myfield != None).select()
``:code

``Row``:inxx
**Row** содержит значения поля.
``
for row in rows:
    print row.myfield
``:code

``Query``:inxx
**Query** это объект, который представляет собой SQL условие "Где":
``
myquery = (db.mytable.myfield != None) | (db.mytable.myfield > 'A')
``:code

``Set``:inxx
**Set** это объект, который представляет собой набор записей. Его наиболее важные методы ``count``, ``select``, ``update``, and ``delete``. Например:
``
myset = db(myquery)
rows = myset.select()
myset.update(myfield='somevalue')
myset.delete()
``:code

``Expression``:inxx

**Expression** это что-то вроде ``orderby`` или ``groupby`` выражение. Класс Field происходит от Expression. Вот пример.
``
myorder = db.mytable.myfield.upper() | db.mytable.id
db().select(db.table.ALL, orderby=myorder)
``:code

### Использование DAL "автономно"
Web2py DAL может использоваться вне среды web2py с помощью
``
from gluon import DAL, Field
# также рассмотреть: from gluon.validators import *
``:code

[[dal_constructor]]
### DAL конструктор
Основное использование:
``
>>> db = DAL('sqlite://storage.sqlite')
``:code

Теперь база данных подключена и соединение сохраняется в глобальной переменной ``db``.

В любое время вы можете получить строку подключения.
``_uri``:inxx
``
>>> print db._uri
sqlite://storage.sqlite
``:code

и имя базы данных
``_dbname``:inxx
``
>>> print db._dbname
sqlite
``:code

Строка соединения называется ``_uri`` потому что это экземпляр унифицированного идентификатора ресурса (Uniform Resource Identifier).

DAL допускает несколько соединений с одной базой данных или с различными базами данных, и даже с базами данных различных типов. На данный момент, мы будем предполагать наличие единой базы данных, так как это самая распространенная ситуация.

#### DAL подпись
``
DAL(uri='sqlite://dummy.db',
    pool_size=0,
    folder=None,
    db_codec='UTF-8',
    check_reserved=None,
    migrate=True,
    fake_migrate=False,
    migrate_enabled=True,
    fake_migrate_all=False,
    decode_credentials=False,
    driver_args=None,
    adapter_args=None,
    attempts=5,
    auto_import=False,
    bigint_id=False,
    debug=False,
    lazy_tables=False,
    db_uid=None,
    do_connect=True,
    after_connection=None,
    tables=None,
    ignore_field_case=True,
    entity_quoting=False,
    table_hash=None)
``:code

[[connection_strings]]
#### Строки подключения (Значение URI параметров)
``connection strings``:inxx

Соединение с базой данных устанавливается путем создания экземпляра объекта DAL:
``
>>> db = DAL('sqlite://storage.sqlite', pool_size=0)
``:code
``db`` не является ключевым словом; это локальная переменная, которая хранит объект подключения ``DAL``. Вы можете дать ему другое имя. Конструктор ``DAL`` требует один аргумент, строку подключения. Строка соединения является единственным кодом web2py, который зависит от конкретной конечной базы данных. Ниже приведены примеры строк соединения для конкретных типов поддерживаемых конечных баз данных (во всех случаях, мы предполагаем, что база данных работает с локального хоста на его порту по умолчанию и называется "test"):

``ndb``:index

-------------
**SQLite**     | ``sqlite://storage.sqlite``
**MySQL**      | ``mysql://username:password@localhost/test``
**PostgreSQL** | ``postgres://username:password@localhost/test``
**MSSQL (legacy)**      | ``mssql://username:password@localhost/test``
**MSSQL (>=2005)**      | ``mssql3://username:password@localhost/test``
**MSSQL (>=2012)**      | ``mssql4://username:password@localhost/test``
**FireBird**   | ``firebird://username:password@localhost/test``
**Oracle**     | ``oracle://username/password@test``
**DB2**        | ``db2://username:password@test``
**Ingres**     | ``ingres://username:password@localhost/test``
**Sybase**     | ``sybase://username:password@localhost/test``
**Informix**   | ``informix://username:password@test``
**Teradata**   | ``teradata://DSN=dsn;UID=user;PWD=pass;DATABASE=test``
**Cubrid**     | ``cubrid://username:password@localhost/test``
**SAPDB**      | ``sapdb://username:password@localhost/test``
**IMAP**       | ``imap://user:password@server:port``
**MongoDB**    | ``mongodb://username:password@localhost/test``
**Google/SQL** | ``google:sql://project:instance/database``
**Google/NoSQL** | ``google:datastore``
**Google/NoSQL/NDB** | ``google:datastore+ndb``
-------------

Обратите внимание на то, что база данных SQLite состоит из одного файла. Если он не существует, то он будет создан. Этот файл блокируется каждый раз при обращении к нему. В случае с MySQL, PostgreSQL, MSSQL, FireBird, Oracle, DB2, Ingres и Informix база данных "test" должна быть создана за пределами web2py. После того, как соединение установлено, web2py сможет создавать, изменять и удалять таблицы соответствующим образом. 

В случае Google/NoSQL опция ``+ ndb`` включает NDB. NDB использует Memcache буфер для чтения данных, доступ к которым часто используется. Это выпорлянется полностью автоматически и сделано на уровне хранилища данных, а не на уровне web2py.

Кроме того, можно установить строку подключения на ``None``. В этом случае DAL не будет подключаться к любой конечной базе данных, но API все еще может быть доступен для тестирования. Примеры этого будут рассмотрены в главе 7.

Иногда вам может понадобиться генерировать SQL-запросы таким образом, как если бы у вас была связь, но без фактического подключения к базе данных. Это можно сделать с помощью

``
db = DAL('...', do_connect=False)
``:code

В этом случае вы сможете вызвать ``_select``, ``_insert``, ``_update``, и ``_delete`` для генерации SQL, но не можете вызвать ``select``, ``insert``, ``update``, и ``delete``. В большинстве случаев вы можете использовать ``do_connect=False`` даже не имея необходимых драйверов баз данных.

Обратите внимание на то, что по умолчанию web2py использует кодировку utf8 для баз данных. Если вы работаете с существующими базами данных, которые ведут себя по-разному, вы должны изменить его с дополнительным параметром вроде ``db_codec``.

``
db = DAL('...', db_codec='latin1')
``:code

В противном случае вы получите билеты UnicodeDecodeError.


#### Пулы соединений
``connection pooling``:inxx

Общепринятым аргументом конструктора DAL является ``pool_size``; он по умолчанию равен нулю.

Поскольку это довольно медленно, чтобы установить новое соединение с базой данных для каждого запроса, web2py реализует механизм пула соединений. После того, как соединение установлено, и страница подана и транзакция завершена, соединение не закрывается, а уходит в пул. При поступлении следующего запроса HTTP, web2py пытается переработать соединение из пула и использовать его для новой транзакции. Если нет доступных соединений в пуле, то устанавливается новое соединение.

Когда запускается web2py, пул всегда пустой. Пул вырастает до минимума между значением ``pool_size`` и максимальным числом одновременных запросов. Это означает, что если ``pool_size = 10`` и наш сервер никогда не получает более 5 одновременных запросов, то фактический размер пула будет расти только до 5. Если ``pool_size = 0`` то пул соединений не используется.

Соединения в пулах распределяются последовательно между потоками, в том смысле, что они могут использовать два различных, но не одновременных потоков. Существует только один пул для каждого процесса web2py.

Параметр ``pool_size`` игнорируется SQLite и Google App Engine.
Пул соединений игнорируется для SQLite, так как это не дает никакой выгоды.

#### Неудачи подключения (число попыток)

Если web2py не удается подключиться к базе данных, то он ожидает 1 секунду и по умолчанию делает еще 5 попыток, прежде чем объявить неудачу. В случае пула соединений вполне возможно, что существует пулированное соединение, которое остается открытым, но не используется в течение некоторого времени, будет закрыто со стороны базы данных. Благодаря функции повторной попытки web2py пытается повторно установить данные разрывы подключений.
Количество попыток устанавливается с помощью параметра числа попыток.

#### Ленивые Таблицы (Lazy Tables)
Настройка ``lazy_tables = True`` обеспечивает значительное повышение производительности. Смотри ниже: [[Ленивые Таблицы #lazy_tables]]

#### Без-Модельные приложения

Использование каталога модели web2py для ваших моделей приложений является очень удобным и продуктивным. С ленивыми таблицами и условными моделями, производительность обычно приемлемая даже для больших приложений. Многие опытные разработчики используют это для производственной среды. 

Тем не менее, можно определить таблицы DAL по требованию внутри функций контроллера или модулей. Это может иметь смысл, когда число или сложность определения таблиц перегружает использование ленивых таблиц и условных моделей.

Это именуется как разработка "без-модели" ("model-less") посредством web2py сообщества.
Это означает отсутствие использования автоматического выполнения python файлов в каталоге модели.
Это не означает отказа от концепции модели, представления и контроллеры.

Web2py автоматически выполняет Python код внутри каталога модели:

+ Модели выполняются автоматически каждый раз, когда обрабатывается запрос
+ Моделям доступна глобальная область видимости web2py.

Модели также делают полезными сессии интерактивной оболочки, когда web2py запускается из командной строки с опцией -M.

Кроме того, помните о сопровождаемости: другие разработчики web2py рассчитывают найти определения модели в каталоге модели.

Используя подход "без модели", вы принимаете ответственность за выполнения этих двух задач по ведению домашнего хозяйства. 
Вы вызываете определения таблицы, когда вы нуждаетесь в них, и обеспечиваете необходимый доступ к глобальной области видимости с помощью текущего объекта. (как описано в главе 4 [[Использование объектом current глобальной области видимости ../04#current_object]] )

Например, типичное приложение без модели может пропустить определения объектов подключения к базе данных в файле модели, но определить таблицы по первому требованию функции контроллера.

Типичный случай заключается в перемещении определений таблицы в файл модуля (файл Python, сохраненный в каталоге модулей).

Если функция, которая определяет набор таблиц, называется ``define_employee_tables()`` и содержиться в модуле, который называется "table_setup.py", то ваш контроллер, который хочет обратиться к таблицам, связанными с записями сотрудников, с тем чтобы сделать SQLFORM должен вызвать функцию ``define_employee_tables()`` перед доступом к любым таблицам. Функция ``define_employee_tables()`` должна получить доступ к объекту подключения базы данных с целью определения таблиц. Именно поэтому вам нужно правильно использовать объект ``current`` в файле модуля, содержащего ``define_employee_tables()``(как упоминалось выше).

#### Реплицируемые базы данных

Первый аргумент ``DAL(...)`` может быть списком URI-адресов. В этом случае web2py пытается подключиться к каждой из них. Основная цель этого заключается в том, чтобы иметь дело с несколькими серверами баз данных и распределить нагрузку между ними). Вот типичный случай использования:

``
db = DAL(['mysql://...1', 'mysql://...2', 'mysql://...3'])
``:code

В этом случае DAL пытается подключиться к первой и, в случае неудачи, он будет пытаться соединиться со второй и третьей. Это также может быть использовано для распределения нагрузки в конфигурации ведущей-ведомой базы данных. Мы поговорим об этом больше в главе 13 в контексте масштабируемости.

#### Зарезервированные ключевые слова
``reserved Keywords``:inxx

``check_reserved`` говорит конструктору проверить имена таблиц и имена столбцов на наличие зарезервированных ключевых слов SQL в целевых серверных базах данных. ``check_reserved`` по умолчанию None.

Это список строк, которые содержат имена адаптеров серверных баз данных.

Имя адаптера является тем же самым, что и используемое в строке подключения DAL. Так что если вы хотите проверить в отношении PostgreSQL и MSSQL, то строка подключения будет выглядеть следующим образом:
``
db = DAL('sqlite://storage.sqlite',
         check_reserved=['postgres', 'mssql'])
``:code

DAL будет сканировать ключевые слова в том же порядке, как и в списке.

Есть два дополнительных варианта "all" и "common". Если вы укажете все ("all"), то он будет проверять по всем известным ключевым словам SQL. Если вы укажете общие ("common"), он будет проверять только по общим ключевым словам, таких как SQL ``SELECT``, ``INSERT``, ``UPDATE`` и т.п.

Для поддерживаемых серверных частей вы можете также указать, что вы также хотите проверять в отношении незарезервированных ключевых слов SQL. В этом случае необходимо добавить в конец ``_nonreserved`` к названию. Например:
``
check_reserved=['postgres', 'postgres_nonreserved']
``:code

Следующие серверные базы данных поддерживают проверку зарезервированных слов.

-----
**PostgreSQL** | ``postgres(_nonreserved)``
**MySQL** | ``mysql``
**FireBird** | ``firebird(_nonreserved)``
**MSSQL** | ``mssql``
**Oracle** | ``oracle``
-----

#### Настройки кваотирования и случаев базы данных (entity_quoting, ignore_field)

Вы также можете использовать явное кваотирование сущностей SQL на уровне DAL.  Это работает прозрачно, так что вы можете использовать одни и те же имена в Python и в схеме DB.

``ignore_field_case = True``
``entity_quoting = True``
Вот пример:
``
db = DAL('postgres://...', ...,ignore_field_case=False, entity_quoting=True)

db.define_table('table1', Field('column'), Field('COLUMN'))

print db(db.table1.COLUMN != db.table1.column).select()
``:code

#### Другие параметры конструктора DAL

##### Расположение папки базы данных
``folder`` – где будут созданы файлы .table. Автоматически устанавливается в пределах web2py. Используйте явный путь при использовании DAL вне web2py

##### Настройки миграции по умолчанию
Миграция подробно описана ниже в Tables [[миграции таблицы #table_migrations]]. Параметры DAL конструктора миграции являются булевыми, затрагивают значения по умолчанию и глобальное поведение.

``migrate = True`` устанавливает поведение по умолчанию при миграции для всех таблиц

``fake_migrate = False`` устанавливает поведение по умолчанию поддельной миграции fake_migrate для всех таблиц

``migrate_enabled = True`` Если задано False, то отключает все миграции

``fake_migrate_all = False`` Если задано True, то поддельные миграции во всех таблицах


#### Эксперимент с web2py оболочкой

Вы можете поэкспериментировать с DAL API используя web2py оболочку (-S [[опция коммандной строки ../04#CommandLineOptions]]).

Начните с создания соединения. Ради примера, вы можете использовать SQLite. Ничего в этой дискуссии не меняется при изменении серверного движка.


[[table_constructor]]
### Конструктор таблиц
``define_table``:inxx ``Field``:inxx

#### Подпись define_table
Подпись для define_table:

Таблицы определяются в DAL с помощью ``define_table``:
``
>>> db.define_table('person',
                    Field('name'),
                    id=id,
                    rname=None,
                    redefine=True
                    common_filter,
                    fake_migrate,
                    fields,
                    format,
                    migrate,
                    on_define,
                    plural,
                    polymodel,
                    primarykey,
                    redefine,
                    sequence_name,
                    singular,
                    table_class,
                    trigger_name)
``:code

Он определяет, сохраняет и возвращает ``Table`` объект под названием "person", содержащей поле (столбец) "name". Этот объект также может быть доступен через ``db.person``, так что вам не нужно ловить возвращаемое значение.

#### ``id``: Замечания по первичному ключу 
Не объявляйте поле, называемое "id", потому что оно все равно создается web2py. Каждая таблица имеет поле с названием "id" по умолчанию. Это целочисленное поле с автоматическим приращением (начиная с 1) используется для перекрестных ссылок и для создания каждой записи уникальным образом, поэтому "id" является первичным ключем. (Примечание: счетчик id начинается с 1 и  задается серверной частью. Например, это не относится к the Google App Engine NoSQL.)

``named id field``:inxx
При желании вы можете определить поле ``type='id'`` и web2py будет использовать это поле как поле id с автоприращением. Это не рекомендуется, кроме случаев доступа к таблицам устаревших баз данных, которые имеют первичный ключ под другим именем.
С некоторыми ограничениями, вы можете также использовать различные первичные ключи используя ``primarykey`` параметр. [[Первичный ключ #primarykey]] будет объяснен ниже в ближайшее время.

#### Множественное ``plural`` и единственное ``singular`` числа
SmartGrid объектам возможно понадобится знать имя таблицы в единственном и множественном числе. Значения по умолчанию являются умными, но эти параметры вы можете конкретизировать. Смотрите SmartGrid для получения дополнительной информации. 
#### Переопределение ``redefine``
Таблицы могут быть определены только один раз, но вы можете заставить web2py переопределить существующую таблицу:

``
db.define_table('person', Field('name'))
db.define_table('person', Field('name'), redefine=True)
``:code

Переопределение может вызвать миграцию, если содержимое поля отличается.

[[record_representation]]
#### Формат ``format``: представление записи

Это не является обязательным, но рекомендуется указать представление формата для записей с помощью ``format`` параметра.
``
>>> db.define_table('person', Field('name'), format='%(name)s')
``:code

или
``
>>> db.define_table('person', Field('name'), format='%(name)s %(id)s')
``:code

или даже более сложные, с помощью функции:
``
>>> db.define_table('person',
                    Field('name'),
                    format=lambda r: r.name or 'anonymous')
``:code

Атрибут формата format будет использоваться для двух целей:
- Для представления записей, имеющих ссылки при выборе/опций в раскрывающихся списках.
- Установите атрибут ``db.othertable.person.represent`` для всех полей, ссылающихся на эту таблицу. Это значит, что SQLTABLE не будет показывать ссылки по id, а вместо этого будет использовать предпочтительный формат представления.

#### ``rname``: Представление записи
``rname`` задает имя конечной базы данных для таблицы. Это создает псевдоним имени таблицы web2py, а ``rname`` это реальное имя, используемое при создании запроса для конечной базы данных.
Проиллюстрируем только одино использование, ``rname`` может быть использован для обеспечения MSSQL полностью квалифицированного по именам таблиц доступа к таблицам, принадлежащих к другим базам данных на сервере: ``rname = 'db1.dbo.table1'``:code

[[primarykey]]
#### Первичный ключ ``primarykey``: Поддержка традиционных таблиц

``primarykey`` помогает поддерживать устаревшие таблицы с существующими первичными ключами, даже из нескольких частей.
Смотрите [[Устаревшие Базы данных #LegacyDatabases]] ниже.

#### ``migrate``, ``fake_migrate``
``migrate`` задает параметры миграции для таблицы. Смотреть [[Миграции Таблицы #table_migrations]] ниже

#### ``table_class``
Если вы определили свой собственный класс Table в качестве подкласса gluon.dal.Table, вы можете предоставить его здесь; это позволяет вам расширить и переопределить методы. Например: ``table_class=MyTable``:code

#### ``sequence_name``
(Необязательно) Имя последовательности пользовательской таблицы (если поддерживается базой данных). Можно создать SEQUENCE (начинающейся с 1 и увеличивающийся на 1) или использовать это для устаревших таблиц с пользовательскими последовательностями. Обратите внимание, что в случае необходимости, web2py будет создавать последовательности автоматически по умолчанию (начинающихся с 1). 

#### ``trigger_name``
(Опционально) Относится к `` sequence_name``. Уместно для некоторых движков баз данных, которые не поддерживают автоприращение числовых полей. 

#### ``polymodel``
Для Google App Engine

#### ``on_define``
``on_define`` является обратным вызовом , срабатывающим когда создается экземпляр lazy_table, хотя он вызывается в любом случае, даже если таблица не является ленивой. Это позволяет динамически вносить изменения в таблицу без потери преимуществ задержанного создания экземпляра. 

Например:
``
db = DAL(lazy_tables=True)
db.define_table('person',
                Field('name'),
                Field('age', 'integer'))

on_define=lambda table: [table.name.set_attributes(requires=IS_NOT_EMPTY(), default=''),
                         table.age.set_attributes(requires=IS_INT_IN_RANGE(0, 120), default=30)]
``:code
Обратите внимание, этот пример показывает, как использовать ``on_define``, но это фактически не нужно. Простые значения ``requires`` могут быть добавлены к определениям поля и таблица все еще будет ленивой. Тем не менее, ``requires``, который принимает объект Set в качестве первого аргумента, такие как IS_IN_DB, будет делать запрос, как ``db.sometable.somefield == some_value``:code, который бы вызвал ``sometable`` определенную в начале. Это является ситуацией, сохраняемой через ``on_define``.

[[lazy_tables]]
#### Ленивые таблицы, основной прирост производительности
``lazy tables``:inxx
web2py модели выполняются перед контроллерами, так что все таблицы определяются в каждом запросе. Не все таблицы необходимы для обработки каждого запроса, так что вполне возможно, что некоторое время тратится при определениях таблиц впустую. Условные модели ([[условные модели, глава 4 ../04#conditional_models]]) могут помочь, но web2py предлагает большой прирост производительности с помощью lazy_tables. Эта возможность означает, что создание таблиц откладывается, пока таблица не будет на самом деле ссылаемой. Включение ленивых таблиц производится при инициализации базы данных с помощью конструктора DAL. Он требует установки параметра ``DAL(...,lazy_tables=True)``. Это одно из наиболее существенных повышений производительности по времени отклика в web2py.

#### Добавление атрибутов к полям и таблицам
Если вам нужно добавить пользовательские атрибуты полей, то вы можете просто сделать:
``db.table.field.extra = {}``:code 

"extra" не является ключевым словом; это пользовательские атрибуты ныне прикрепленные к объекту поля. Вы можете сделать это с таблицами также, но они  должны предворяться знаком подчеркивания, чтобы избежать конфликта имен с полями: 

``db.table._extra = {} ``:code


[[field_constructor]]
### Конструктор Field
``Field constructor``:inxx
Вот значения по умолчанию конструктора Field:
``
Field(fieldname, type='string', length=None, default=None,
      required=False, requires='<default>',
      ondelete='CASCADE', notnull=False, unique=False,
      uploadfield=True, widget=None, label=None, comment=None,
      writable=True, readable=True, update=None, authorize=None,
      autodelete=False, represent=None, compute=None,
      uploadfolder=None, uploadseparate=None, uploadfs=None, rname=None)
``:code

Не все из них актуальны для каждого поля. "length" имеет значение только для полей типа "string". "uploadfield" и "authorize" имеют значения только для полей типа "upload". "ondelete" имеет значение только для полей типа "reference" и "upload".
- ``length`` устанавливает максимальную длину поля типа "string", "password" или "upload".  Если ``length`` не задано, то используется значение по умолчанию, но значение по умолчанию не гарантирует обратную совместимость. ''Чтобы избежать нежелательных миграции при обновлении, мы рекомендуем вам всегда указывать длину полей строк, пароля и загрузки.''
- ``default`` устанавливает значение по умолчанию для поля. Значение по умолчанию используется при выполнении вставки, если значение не указано явно. Он также используется для предварительного заполнения формы, построенных из таблицы с использованием SQLFORM. Обратите внимание, что скорее всего взамен фиксированного значения по умолчанию может быть функция (в том числе лямбда-функция), которая возвращает значение соответствующего типа для поля. В этом случае функция вызывается один раз для каждой вставляемой записи, даже при наличии нескольких вставляемых записей в одной транзакции.
- ``required`` сообщает DAL, что вставка не должна быть разрешена в этой таблице, если значение для этого поля не указано явно.
- ``requires`` является валидатором или списком валидаторов. Параметр не используется DAL, но он используется SQLFORM. Валидаторы по умолчанию для заданных типов полей приведены в следующем разделе.
-------
Обратите внимание на то , что ``requires=...`` обеспечивается на уровне форм, ``required=True`` обеспечивается на уровне DAL (вставка), в то время как ``notnull``, ``unique`` и ``ondelete`` применяются на уровне базы данных. Несмотря на то, что они иногда могут показаться излишними, важно поддерживать различие при программировании с помощью DAL.
-------
- ``uploadfolder`` пока по умолчанию используется ``None``, большинство адаптеров баз данных будет по умолчанию загружать файлы в os.path.join(request.folder, 'uploads'). MongoAdapter кажется, не будет делать это в настоящее время.
- ``rname`` обеспечивает чтобы поле имело "реальное имя" ("real name"), имя для поля, известного адаптера базы данных; когда поле используется, то значение rname это то значение, которое отправляется в базу данных. Имя для поля web2py является в действительности псевдонимом.
``ondelete``:inxx
- ``ondelete`` переводится как выражение SQL "ON DELETE". По умолчанию он установлен на "CASCADE". Это сообщает базе данных, чтобы при удалении заданной записи также необходимо удалить все связанные записи. Чтобы отключить эту функцию, задайте параметру ``ondelete`` значение "NO ACTION" или "SET NULL".
- ``notnull=True`` переводится как выражение SQL "NOT NULL". Он ограждает базу данных от вставки нулевых значений для поля.
- ``unique=True`` переводится как выражение SQL "UNIQUE" и он гарантирует, что значения этого поля являются уникальными в пределах таблицы. Это обеспечивается на уровне базы данных.
- ``uploadfield`` применяется только к полям типа "upload". Поле типа "upload" хранит имя файла, сохраненного в другом месте, по умолчанию в папке приложения "uploads/" файловой системы. Если ``uploadfield`` задан как True, то файл хранится в поле двоичных объектов в пределах одной таблицы и значение ``uploadfield`` это имя поля двоичных объектов. Этот вопрос будет обсуждаться более подробно позже в контексте SQLFORM.
- ``uploadfolder`` по умолчанию является папкой приложения "uploads/". Если задать другой путь, то файлы будут загружены в другую папку. 
-------
Например поле,
``
Field(...,uploadfolder=os.path.join(request.folder,'static/temp'))
``:code
будет загружать файлы в папку "web2py/applications/myapp/static/temp".
-------
- ``uploadseparate`` Если занано значение True, поле будет загружать файлы в различные подпапки внутри папки ''uploadfolder''. Предназначено для оптимизации во избежание слишком большого количества файлов в одной той же самой папке folder/subfolder. ВНИМАНИЕ: Вы не можете изменить значение ``uploadseparate`` с True на False без разрушения ссылок на существующие загрузки. web2py либо использует отдельные вложенные папки, либо нет. Изменение поведения после того, как файлы были загружены будет препятствовать web2py при получении этих файлов. Если это произойдет, то можно переместить файлы и исправить эту проблему, но этот способ не описывается здесь.
- ``uploadfs`` позволяет указать другую файловую систему, куда загружать файлы, включая хранилище Amazon S3 или удаленное хранилище SFTP. Данный параметр требует установленный PyFileSystem. ``uploadfs`` должен указывать на ``PyFileSystem``. ``PyFileSystem``:inxx ``uploadfs``:idxx
- ``widget`` должен быть одним из доступных виджет объектов, в том числе одним из пользовательских виджетов, например: ``SQLFORM.widgets.string.widget``. Список доступных виджетов будет обсуждаться позже. Каждый тип поля имеет виджет по умолчанию.
- ``label`` является строкой (или помощником или чем-то, что может быть сериализовано в строку), содержащей метку и которая будет использоваться для этого поля в автоматически генерируемых формах.
- ``comment``  является строкой (или помощником или чем-то, что может быть сериализовано в строку), содержащей связанный с этим полем комментарий и который будет отображаться справа от поля ввода в автоматически сгенерированных формах.
- ``writable`` объявляет поле в формах, предназначенное для записи.
- ``readable`` объявляет поле в формах, предназначенное для чтения. Если поле не предназначено ни для чтения, ни для записи, то оно не будет отображаться при создании и обновлении формы.
- ``update`` содержит значение по умолчанию для этого поля, когда запись является обновленной.
- ``compute`` является дополнительной функцией. Если запись вставлена или обновлена, то данная функция вычислений будет выполнена, и поле будет заполнено результатом действия функции. Запись передается в функцию вычисления в виде словаря ``dict``, и словарь dict не будет включать в себя текущее значение этого, или любого другого вычисляемого поля.
- ``authorize`` может быть использован при необходимости контроля доступа для соответствующего поля, только для полей загрузки "upload". Это будет обсуждаться более подробно в контексте аутентификации и авторизации.
- ``autodelete`` задает автоматическое удаление соответствующего загруженного файла при удалении ссылки на файл. Только для полей загрузки "upload". Тем не менее, удаление записей  самой базой данных при выполнении соответсвующей операции CASCADE, не будет вызывать автоудаление web2py. В Web2py группе Google имеется обсуждение обходных путей.
- ``represent`` может быть None или может указывать на функцию, которая принимает значение поля и возвращает альтернативное представление для значения поля. 
-------
Пример:
``
db.mytable.name.represent = lambda name, row: name.capitalize()
db.mytable.other_id.represent = lambda id, row: row.myfield
db.mytable.some_uploadfield.represent = lambda value, row: A('get it', _href=URL('download', args=value))
``:code
-------


[[field_types]]
#### Типы полей
``field types``:inxx

----------
**Тип поля** | **Валидаторы поля по умолчанию**| **Описание**
``string`` | ``IS_LENGTH(length)``| Строка (длина по умолчанию 512)
``text`` | ``IS_LENGTH(65536)``| Текст
``blob`` | ``None``| Большой двочный объект (big large object)
``boolean`` | ``None``| Булевое значение
``integer`` | ``IS_INT_IN_RANGE(-1e100, 1e100)``| Целое число
``double`` | ``IS_FLOAT_IN_RANGE(-1e100, 1e100)``| Действительное число
``decimal(n,m)`` | ``IS_DECIMAL_IN_RANGE(-1e100, 1e100)``| Десятичная дробь
``date`` | ``IS_DATE()``| Дата
``time`` | ``IS_TIME()``| Время
``datetime`` | ``IS_DATETIME()``| Дата-время
``password`` | ``None``| Пароль
``upload`` | ``None``| Поле загрузки
``reference <table>``  | ``IS_IN_DB(db, table.field, format)``| Ссылка
``list:string`` | ``None``| Список строк
``list:integer`` | ``None``| Список целых
``list:reference <table>`` | ``IS_IN_DB(db, table.field, format, multiple=True)``| список ссылок
``json`` | ``IS_JSON()``| Формат json
``bigint`` | ``None``| Большое целое
``big-id`` | ``None``| Длинный индентификатор
``big-reference`` | ``None``| Длинная ссылка
---------

Десятичный тип поля требует и возвращает значения в виде объектов класса ``Decimal``, как это определено в Python модуле ``decimal``. SQLite не обрабатывает тип ``decimal``, таким образом внутренне мы рассматриваем его как ``double``. (n,m) это количество цифр в целой и в дробной части соответственно.

Типы ``big-id`` и ``big-reference`` поддерживаются только некоторыми движками баз данных и являются экспериментальными. Они обычно не используются в качестве типов полей, за исключением использования для устаревших таблиц, однако, конструктор DAL имеет аргумент ``bigint_id``, который при установке на ``True`` преобразует тип полей ``id`` и ``reference`` в ``big-id`` и ``big-reference`` соответственно.

Поля с типом ``list:<тип>`` являются особенным, потому что они разработаны, чтобы воспользоваться преимуществами определенных функций денормализации на NoSQL (в случае с Google App Engine NoSQL, типы полей ``ListProperty`` и ``StringListProperty``) и  обратного-портирования (back-port) данных типов полей для всех других поддерживаемым реляционных баз данных. В реляционных базах данных списки хранятся в виде поля ``text``. Элементы разделяются символом ``|`` и каждый символ ``|``, находящийся в элементе строки должен экранироваться путем удваивания ``||``. Они обсуждаются в отдельном разделе.

Тип поля ``json`` не требует много пояснений. Он может хранить любой сериализованный объект в формате JSON. Он предназначен специально для работы с MongoDB и обратного портирования на другие адаптеры базы данных для портативности.


``blob``:inxx
Поля ``blob``(big large object) также являются специальными. По умолчанию, двоичные данные кодируются в base64 перед сохранением в фактическое поле базы данных и декодируются при извлечении. Это оказывает негативное влияние, используя на 33% больше места для хранения, чем это необходимо в blob  полях, но имеет преимущество в создании связи независимо от определенных соглашений по экранированию конечных баз данных.

#### Поле времени выполнения и таблица модификации

Большинство атрибутов полей и таблиц могут быть изменены после их определения:

``
db.define_table('person',
                Field('name', default=''),
                format='%(name)s')

db.person._format = '%(name)s/%(id)s'
db.person.name.default = 'anonymous'
``
(Обратите внимание, что атрибуты таблиц, как правило, начинается с префикса подчеркивания, чтобы избежать конфликта с возможными именами полей).

Вы можете получить список таблиц, которые были определены для данного соединения с базой данных:

``tables``:inxx
``
>>> print db.tables
['person']
``:code

Вы также можете перечислить поля, которые были определены для данной таблицы:

``fields``:inxx
``
>>> print db.person.fields
['id', 'name']
``:code


Вы можете запросить тип таблицы:

``Table``:inxx
``
>>> print type(db.person)
<class 'gluon.sql.Table'>
``:code

и вы можете получить доступ к таблицы из DAL соединения используя:
``
>>> print type(db['person'])
<class 'gluon.sql.Table'>
``:code

Точно так же вы можете получить доступ к полям по их имени несколькими эквивалентными способами:
``
>>> print type(db.person.name)
<class 'gluon.sql.Field'>
>>> print type(db.person['name'])
<class 'gluon.sql.Field'>
>>> print type(db['person']['name'])
<class 'gluon.sql.Field'>
``:code

Получив поле, вы можете получить доступ к атрибутам, установленным в его определении:
``
>>> print db.person.name.type
string
>>> print db.person.name.unique
False
>>> print db.person.name.notnull
False
>>> print db.person.name.length
32
``:code

в том числе его родительскую таблицу, имя таблицы и родительское подключение:
``
>>> db.person.name._table == db.person
True
>>> db.person.name._tablename == 'person'
True
>>> db.person.name._db == db
True
``:code

Поле также имеет методы. Некоторые из них используются для построения запросов, и мы рассмотрим их позже.
Особым методом объекта поля является ``validate``, который вызывает валидаторы для поля.

``
print db.person.name.validate('John')
``

возвращает кортеж ``(value, error)``. ``error`` равняется ``None`` если входные данные прошли проверку.



[[table_migrations]]
### Миграции

``migrations``:inxx

Метод ``define_table`` проверяет, существует ли или нет соответствующая таблица. Если это не так, то он генерирует SQL-код для ее создания и выполняет его. Если таблица все же существует, но отличается от определяемой, то он генерирует SQL-код, чтобы изменить таблицу и выполняет его. Если изменяется тип поля, но не имя, то он попытается преобразовать данные (Если вы не хотите этого, то вам нужно переопределить таблицу дважды, в первый раз, позволяя web2py отбросить поле путем его удаления, и во второй раз добавляя вновь определенное поле таким образом, что web2py может создать его.). Если таблица существует и соответствует текущему определению, то он оставит его в покое. Во всех случаях он будет создавать объект ``db.person``, который представляет таблицу.

Мы называем это поведение как "миграция" ("migration"). web2py регистрирует все миграции и попытки миграции в файле "databases/sql.log".

Первый аргумент ``define_table`` всегда является именем таблицы. Остальными безымянными аргументами являются поля (Field). Функция также принимает необязательный аргумент - ключевое слово с именем "migrate":
``
>>> db.define_table('person', Field('name'), migrate='person.table')
``:code

Значением migrate является имя файла (в папке "databases" приложения) где web2py хранит внутреннюю миграционную информацию для этой таблицы.
Эти файлы очень важны и не должны удаляться до тех пор, пока соответствующие таблицы существуют.  В тех случаях, когда таблица была отброшена и соответствующий файл по-прежнему существует, он может быть удален вручную. По умолчанию, миграция имеет значение True. Это заставляет web2py генерировать имя файла из хэш строки подключения. Если миграция имеет значение False, то миграция не выполняется, и web2py предполагает, что таблица существует в хранилище данных и содержит (по крайней мере) поля, перечисленные в ``define_table``.
Передовая практика заключается в задании явного имени таблицы миграции.

Здесь не может быть две таблицы в одном и том же приложении с аналогичным именем файла миграции.

Класс DAL также принимает аргумент "migrate", который определяет значение migrate по умолчанию для вызовов в ``define_table``. Например,
``
>>> db = DAL('sqlite://storage.sqlite', migrate=False)
``:code

будет устанавливать значение migrate по умолчанию на False всякий раз, когда ``db.define_table`` вызывается без аргумента migrate.

------
Обратите внимание на то, что web2py мигрирует только новые столбцы, удаленные столбцы, а также столбцы с измененным типом (за исключением SQLite). web2py не выполняет миграцию такие изменений в атрибутах, как изменения значений ``default``, ``unique``, ``notnull``, и ``ondelete``.
------

Миграции могут быть отключены для всех таблиц одновременно:

``
db = DAL(..., migrate_enabled=False)
``

Это рекомендуемое поведение, когда два приложения имеют общую базу данных. Только одно из этих двух приложений должен выполнять миграции, а другому следует отключить их.

### Фиксация нарушенных миграций
``fake_migrate``:inxx

Есть две общие проблемы, связанные с миграциями и есть способы восстановления после них.

Одна из проблем специфична для SQLite. SQLite не применяет типы столбцов и не может отбросить столбцы. Это означает, что если у вас есть столбец строкового типа и вы удалите его, то он на самом деле не удаляется. Если вы добавляете столбец снова с другим типом (например, datetime ) вы получите в конечном итоге столбец datetime, который содержит строки (барахло для практических целей). web2py не пожалуется на это, потому что не знает, что находится в базе данных, пока он не пытается получить записи и не потерпит неудачу.

Если web2py возвращает ошибку в функции gluon.sql.parse при выборе записей, это проблема: появляются поврежденные данные в столбце из-за указанной выше проблемы.

Решение состоит в обновлении всех записей таблицы и обновления значений в столбце на None.

Другая проблема является более общией, но типичной для MySQL. MySQL не позволяет более одного оператора ALTER TABLE в транзакции. Это означает, что web2py должен разбить сложные операции на более мелкие (один ALTER TABLE за раз) и зафиксировать один кусок в это же время. Поэтому возможно, что одна часть сложной транзакции получит фиксацию, а другая часть потерпит неудачу, оставляя web2py в испорченном состоянии. Почему части транзакции потерпит неудачу? Потому что, например, она может включать в себя изменение таблицы и преобразования строкового столбца в столбец даты и времени, web2py попытается преобразовать данные, но данные не могут быть преобразованы. Что произойдет с web2py? Он будет поставлен в тупик о том, какая именно структура таблицы на самом деле хранится в базе данных.

Решение состоит из отключение миграций для всех таблиц и включения поддельных миграций:
``
db.define_table(...., migrate=True, fake_migrate=True)
``:code

Это позволит web2py перестроить метаданные о таблице в соответствии с определением таблицы. Попробуйте несколько определений таблицы, чтобы увидеть, какая из них работает (одна перед неудачной миграцией, и одна после неудачной миграции). После успешного завершения удалите ``fake_migrate=True`` параметр.

Прежде чем пытаться исправить проблемы миграции благоразумно сделать копию файлов "applications/yourapp/databases/*.table".

Проблемы миграции также могут быть фиксированными для всех таблиц сразу:

``
db = DAL(..., fake_migrate_all=True)
``:code

Это также терпит неудачу, если модель описывает таблицы, которые не существуют в базе данных, но это может помочь сузить проблему.

### Краткое описание миграционного контроля

Логика различных аргументов миграции обобщена в этом псевдокоде:
``
if DAL.migrate_enabled and table.migrate:
   if DAL.fake_migrate_all or table.fake_migrate:
       perform fake migration
   else:
       perform migration
``:code

### Вставка ``insert``

Получив таблицу, вы можете вставлять записи

``insert``:inxx
``
>>> db.person.insert(name="Alex")
1
>>> db.person.insert(name="Bob")
2
``:code

при вставке возвращаются уникальные значения "id" для каждой из вставленной записи.

Вы можете обрезать (truncate) таблицу, то есть, удалить все записи и сбросить счетчик id.

``truncate``:inxx
``
>>> db.person.truncate()
``:code

Теперь, если вы вставите запись снова, то отсчет начнется с 1 (это зависит от конкретной базы данных и не относится к Google NoSQL):
``
>>> db.person.insert(name="Alex")
1
``:code

Обратите внимание, вы можете передать некоторые параметры ``truncate``, например, чтобы соотщить SQLITE перезапустить счетчик id.

``
db.person.truncate('RESTART IDENTITY CASCADE')
``:code

Аргумент является необработанным SQL-кодом и поэтому зависит от конкретного движка базы данных.

``bulk_insert``:inxx
web2py также предоставляет метод массовой вставки bulk_insert
``
>>> db.person.bulk_insert([{'name': 'Alex'}, {'name': 'John'}, {'name': 'Tim'}])
[3, 4, 5]
``:code

Она принимает список из словарей с именами полей и их значениями, которые подлежат вставке, и выполняет несколько вставок одновременно. Он возвращает идентификаторы вставленных записей. На поддерживаемых реляционных базах данных не существует каких-либо преимуществ в использовании этой функции в отличие от цикла и выполнения отдельных вставок, а вот на Google App Engine NoSQL, это дает основное преимущество в скорости.

### Фиксация ``commit`` и откат ``rollback`` изменений

Операции создания, отбрасывания, вставки, обрезания, удаления или обновления фактически не фиксируются до тех пор, пока web2py выдаст команду фиксировать. В моделях, представлениях и контроллерах, web2py делает это за вас, но в модулях вам потребуется делать фиксации самостоятельно.

``commit``:inxx
``
>>> db.commit()
``:code

Чтобы проверить это, давайте вставим новую запись:
``
>>> db.person.insert(name="Bob")
2
``:code

и откатим, т.е. проигнорируем все операции после последней фиксации:

``rollback``:inxx
``
>>> db.rollback()
``:code

Если вы теперь вставите снова, то счетчик вновь будет установлен на 2, так как предыдущая вставка откатывается.
``
>>> db.person.insert(name="Bob")
2
``:code

Код в моделях, представлениях и контроллерах заключен в web2py код, который выглядит следующим образом (псевдокод):
``
try:
    выполнение моделей, функции контроллера и представления
except:
    откат всех подключений
    запись трэйсбэка (отслеживания ошибки) в лог
    отправка билета (страницы с кодом ошибки) посетителю
else:
    фиксация всех подключений
    сохранение куки, сессий и возврат страницы
``:code

Таким образом, в моделях, представлениях и контроллерах web2py нет необходимости в явном вызове ``commit``  или ``rollback``, если вам не требуется более детальный контроль.
Тем не менее, в модулях вам нужно будет использовать ``commit()``.

### Сырой SQL

#### Расчет времени запросов

Все запросы автоматически просчитываются по времени web2py. Переменная ``db._timings`` является списком кортежей. Каждый кортеж содержит необработанный запрос SQL, который передается драйверу базы данных и время выполнения запроса в секундах. Эта переменная может быть отображена в представлениях с помощью панели инструментов:

``
{{=response.toolbar()}}
``

#### Метод ``executesql``

DAL позволяет явно выдавать SQL операторы.

``executesql``:inxx
``
>>> print db.executesql('SELECT * FROM person;')
[(1, u'Massimo'), (2, u'Massimo')]
``:code

В этом случае возвращаемые значения не разбираются или преобразуются через DAL, и формат зависит от конкретного драйвера базы данных. Такое использование с выборкой данных, как правило, не требуется, но чаще встречается с индексами.
Метод ``executesql`` принимает четыре необязательных аргумента: ``placeholders``, ``as_dict``, ``fields`` и ``colnames``.
``placeholders`` является необязательной последовательностью значений, которые будут замещены, или, если эта функция поддерживается драйвером базы данных, словарем с ключами, соответствующими именованным местозаполнителям в вашем SQL.

Если ``as_dict`` установлен на True, то результирующий курсор, возвращаемый драйвером базы данных будет преобразован в последовательность словарей, ключированных именами полей базы данных. Результаты возвращенные с ``as_dict = True`` являются теми же самыми, которые возвращается при применении **. as_list()** для нормального выбора.
``
[{field1: value1, field2: value2}, {field1: value1b, field2: value2b}]
``:code

аргумент ``fields`` явялется списком объектов DAL Field, которые соответствуют возвращаемым из базы данных полям. Объекты Field должны быть частью одного или нескольких объектов Table, определенных в объекте DAL. Список ``fields`` может включать в себя один или несколько объектов DAL Table в дополнение или взамен включения объектов Field, или он может быть только одной таблицей (нет в списке). В этом случае объекты Field будут извлечены из таблиц(ы).

Вместо уточнения аргумента ``fields``, аргумент ``colnames``  может быть указан в виде списка имен полей в следующем формате tablename.fieldname. Опять же, они должны представлять таблицы и поля, определенные в объекте DAL.

Кроме того, можно указать оба ``fields`` и связанный с ним ``colnames``. В этом случае, ``fields`` может также включать в себя объекты DAL Expression в дополнение к объектам Field. Для объектов Field в "полях", связанный с ним `` colnames`` должны еще быть в tablename.fieldname формате.
Для Expression объектов в ``fields``, связанные с ним ``colnames`` могут быть любыми произвольными метками.

Обратите внимание, объекты DAL Table ссылаемые через ``fields`` или ``colnames`` могут быть фиктивными таблицами и не должны представлять какие-либо реальные таблицы в базе данных. Кроме того, обратите внимание, что ``fields`` и ``colnames`` должны идти в том же порядке, что и поля в курсоре результатов, возвращаемых из базы данных.


#### Атрибут ``_lastsql``

Если SQL был выполнен вручную с помощью executesql или SQL-код был сгенерирован через DAL, то вы всегда можете найти код SQL в атрибуте ``db._lastsql``. Это полезно для целей отладки:

``_lastdb``:inxx
``
>>> rows = db().select(db.person.ALL)
>>> print db._lastsql
SELECT person.id, person.name FROM person;
``:code

-------
web2py никогда не генерирует запросы, используя оператор "*". web2py всегда явно указывает при выборе полей.
-------

### Метод ``drop``

Наконец, вы можете отбрасывать таблицы и все данные будут потеряны:

``drop``:inxx
``
>>> db.person.drop()
``:code

Примечание для SQLite: web2py не будет заново создавать отброшенную таблицу, пока вы не перейдете по файловой системе в каталог баз данных вашего приложения, и не удалите файл, связанный с отброшенной таблицей. 

### Индексы

В настоящее время DAL API не предоставляет команду для создания индексов таблиц, но это можно сделать с помощью команды ``executesql``. Это происходит потому, что существование индексов может сделать миграции сложным, и лучше иметь дело с ними в явном виде. Индексы могут быть необходимы для тех полей, которые используются в повторяющихся запросах.

Ниже приведен пример того, как [[создать индекс с помощью SQL в SQLite http://www.sqlite.org/lang_createindex.html]]:
``
>>> db = DAL('sqlite://storage.sqlite')
>>> db.define_table('person', Field('name'))
>>> db.executesql('CREATE INDEX IF NOT EXISTS myidx ON person (name);')
``:code

Другие диалекты базы данных имеют очень похожие синтаксисы, но могут не поддерживать необязательную "IF NOT EXISTS" директиву.

[[LegacyDatabases]]
### Унаследованные базы данных и ключированные таблицы

web2py может подключаться к унаследованным базам данных при некоторых условиях.

Самый простой способ, когда будут выполнены эти условия:
- Каждая таблица должена иметь уникальное автоприращаемое целочисленное поле, называемое "id"
- Записи должны быть привязаны исключительно с помощью "id" поля.

При обращении к существующей таблице, то есть к таблица не созданной web2py в текущем приложении, всегда устанавливается ``migrate=False``.

Если унаследованная таблица имеет автоприращаемое целочисленное поле, но оно не называется "id", то web2py по-прежнему может получить доступ к нему, но определение таблицы должно содержать в явном виде ``Field('....','id')``, где вместо точек ... подставляется имя автоприращаемого целочисленного поля.

``keyed table``:inxx

И, наконец, если унаследованная таблица использует первичный ключ, который не является автоприращаемым id полем, то существует возможность использовать "ключированную таблицу", например:

``
db.define_table('account',
                Field('accnum','integer'),
                Field('acctype'),
                Field('accdesc'),
                primarykey=['accnum','acctype'],
                migrate=False)
``:code

- ``primarykey`` список имен полей, которые составляют первичный ключ.
- Все первичные ключевые поля имеют установку ``NOT NULL``, даже если это не указано.
- Ключированные таблицы могут ссылаться только на другие ключированные таблицы.
- Ссылочные поля должны использовать формат ``reference tablename.fieldname``.
- Функция ``update_record`` недоступна для Строк ключированных таблиц.

-------
В настоящее время ключированные таблицы поддерживаются только для DB2, MS-SQL, Ingres и Informix, но будут добавлены другие движки.
-------

На момент написания, мы не можем гарантировать, что атрибут ``primarykey`` работает с каждой существующей унаследованной таблицей и каждой поддерживаемой конечной базой данных.
Для простоты, мы рекомендуем, если это возможно, создать представление базы данных, которое имеет автоприращаемое id поле.


### Распределенные транзакции
``distributed transactions``:inxx

------
На момент написания эта возвожность поддерживается только PostgreSQL, MySQL и Firebird, так как они предоставляют API для двухфазных фиксаций.
------

Если у вас есть два (или более) подключений к отдельным базам данных PostgreSQL, например:
``
db_a = DAL('postgres://...')
db_b = DAL('postgres://...')
``:code

В ваших моделях или контроллерах, вы можете зафиксировать их одновременно:
``
DAL.distributed_transaction_commit(db_a, db_b)
``:code

В случае неудачи, эта функция выполняет откат и поднимает исключение (``Exception``).

В контроллерах, когда действие возвращает результат, если у вас есть два различных соединения и вы не вызывали вышеприведенную функцию, то web2py фиксирует их по отдельности. Это означает, что существует вероятность того, что одна из фиксаций может завершиться успешно, а другая потерпеть неудачу. Распределенная транзакция предотвращает от такого происшествия.

### Дополнительная информация по загрузкам

Рассмотрим следующую модель:
``
>>> db.define_table('myfile',
                    Field('image', 'upload', default='path/'))
``:code

В случае поля 'загрузки', значение атрибута default при необходимости может быть задано как путь (абсолютный путь или относительный путь к текущей папке приложения) и файл изображения по умолчанию будет копироваться по заданному пути. Новая копия делается для каждой новой записи, которая не определяет изображение.

Обычно вставка выполняется автоматически с помощью SQLFORM или формы crud (которая представляет собой SQLFORM), но иногда у вас уже есть файл в файловой системе и вы хотите загрузить его программно. Это может быть сделано таким образом:
``
>>> stream = open(filename, 'rb')
>>> db.myfile.insert(image=db.myfile.image.store(stream, filename))
``:code

Кроме того, можно вставить файл более простым способом и иметь автоматически вызываемый хранилищем метод вставки:

``
>>> stream = open(filename, 'rb')
>>> db.myfile.insert(image=stream)
``:code

В этом случае имя файла получается из объекта stream, если таковой имеется.

Метод ``store`` объекта поля загрузки принимает stream файла и имя файла. Он использует имя файла, чтобы определить расширение (тип) файла, создает новое временное имя для файла (в соответствии с web2py механизмом загрузки) и загружает содержимое файла в этот новый временный файл (в папку uploads, если не указано иное). Он возвращает новое временное имя, которое затем хранится в поле ``image`` из таблицы ``db.myfile``.

Обратите внимание, если файл должен быть сохранен в соответствующем blob поле, а не в файловой системе, метод ``store()`` не будет вставлять файл в blob поле (потому что ``store()`` вызывается перед вставкой), поэтому файл должен явно вставляться в blob поле:
``
>>> db.define_table('myfile',
                    Field('image', 'upload', uploadfield='image_file'),
                    Field('image_file', 'blob'))
>>> stream = open(filename, 'rb')
>>> db.myfile.insert(image=db.myfile.image.store(stream, filename),
                     image_file=stream.read())
``:code


Противоположностью ``.store`` является ``.retrieve``:

``
>>> row = db(db.myfile).select().first()
>>> (filename, stream) = db.myfile.image.retrieve(row.image)
>>> import shutil
>>> shutil.copyfileobj(stream, open(filename, 'wb'))
``

### Объекты ``Query``, ``Set``, ``Rows``

Давайте снова рассмотрим ранее определенные таблицы (и сброшенные) и вставим три записи:
``
>>> db.define_table('person', Field('name'))
>>> db.person.insert(name="Alex")
1
>>> db.person.insert(name="Bob")
2
>>> db.person.insert(name="Carl")
3
``:code

Вы можете сохранить таблицу в переменной. Например, в переменной ``person``, вы могли бы сделать:

``Table``:inxx
``
>>> person = db.person
``:code

Вы также можете сохранить поля в такую переменную как ``name``.  Например, вы могли бы также сделать:

``Field``:inxx
``
>>> name = person.name
``:code

Вы даже можете построить запрос (используя операторы вроде ==, !=, <, >, <=, >=, like, belongs) и сохранить запрос в переменной ``q``:

``Query``:inxx
``
>>> q = name == 'Alex'
``:code

Когда вы вызываете ``db`` с запросом, вы определяете набор (Set) записей. Вы можете сохранить его в переменной ``s`` и написать:

``Set``:inxx
``
>>> s = db(q)
``:code

Обратите внимание на то, что до сих пор ни один запрос к базе данных еще не был выполнен. DAL + Query просто определяют набор записей в этой базе данных, который соответствуют запросу.
web2py из запроса определяет какая таблица (или таблицы) вовлечены и, по факту, нет необходимости указывать что-либо еще.

### Метод ``select``

Допустим задан объект Set, в переменной``s``, тогда вы можете получить записи с помощью команды ``select``:

``Rows``:inxx ``select``:inxx
``
>>> rows = s.select()
``:code

``Row``:inxx
Она возвращает итерируемый объект класса ``gluon.sql.Rows`` элементы которого являются объектами Row. ``gluon.sql.Row`` объекты действуют как словари, но их элементы также могут быть доступны в качестве атрибутов, как в ``gluon.storage.Storage``. Объекты класса Row отличаются от объектов класса Storage тем, что их значения предназначены только для чтения.

Объект Rows позволяет перебрать в цикле результат выборки и, например, напечатать выбранные значения полей для каждой строки:
``
>>> for row in rows:
        print row.id, row.name
1 Alex
``:code

Вы можете сделать все шаги в одном выражении:
``
>>> for row in db(db.person.name == 'Alex').select():
        print row.name
Alex
``:code

``ALL``:inxx

Команда select может принимать аргументы. Все безымянные аргументы интерпретируются как имена полей, которые вы хотите достать. Например, вы сможете явным образом сделать выборку поля "id" и поля "name":
``
>>> for row in db().select(db.person.id, db.person.name):
        print row.name
Alex
Bob
Carl
``:code

Атрибут таблицы ALL позволяет указать все поля:
``
>>> for row in db().select(db.person.ALL):
        print row.name
Alex
Bob
Carl
``:code

Обратите внимание на то, что нет никакой строки запроса, передаваемой в базу данных. web2py поймет, что если вам нужны все поля таблицы person без дополнительной информации, тогда вам понадобяться все записи таблицы person.

Эквивалентный альтернативный синтаксис выглядит следующим образом:
``
>>> for row in db(db.person.id > 0).select():
        print row.name
Alex
Bob
Carl
``:code

и web2py поймет, что если вы запрашиваете все записи таблицы person (id> 0) без дополнительной информации, то вам нужны все поля таблицы person.

Возьмем одну строку

``
row = rows[0]
``

вы можете извлечь её значения, используя несколько эквивалентных выражений:

``
>>> row.name
Alex
>>> row['name']
Alex
>>> row('person.name')
Alex
``

Последний синтаксис особенно удобен при выборе EN выражения вместо столбца. Покажем это позже.

Вы можете также сделать
``
rows.compact = False
``
и отключить компактную нотацию
``
row[i].name
``
и включить, взамен этого, менее компактную нотацию:
``
row[i].person.name
``
Да, это необычно и редко требуется.

Объекты Row также имеют два важных метода:
``
row.delete_record()
``
и 
``
row.update_record(name="new value")
``

#### Использование итератор-базированного метода select для более низкого использования памяти

Python "итераторы" относятся к типу "ленивой оценки". Они 'скармливают' данные один шаг за раз; традиционные циклы Python создают весь набор данных в памяти перед перебором цикла. 

Традиционным использованием Select является:
``
for row in db(db.table.id > 0).select():
    rtn = row
``:code

но для большого количества строк, использование итератор-основанной альтернативы имеет драматически меньшее использование памяти:

``
for row in db(db.table.id > 0).iterselect():
    rtn = row
``:code
Тестирование показывает, что это примерно на 10% быстрее, даже на машинах с большой оперативной памятью.


#### Визуализация строк с использованием представления

Вы можете переписать строки, возвращаемые select для получения преимуществ форматирования информации, содержащейся в настройке представления полей. 

``
rows = db(query).select()  
repr_row = rows.render(0)
``:code

Если вы не указали индекс, то вы получите генератор для перебора всех строк:

``
for row in rows.render():
    print row.myfield
``:code

Можно также применить к срезам:

``
for row in rows[0:10].render():
    print row.myfield
``:code

Если вы хотите преобразовать выбранные поля через их "represent" атрибут, то вы можете перечислить их в "fields" аргументе:

``
repr_row = row.render(0, fields=[db.mytable.myfield])
``:code

Обратите внимание, он возвращает преобразованную копию исходного Row, так что здесь нет update_record (которые вы не хотели бы в любом случае) или delete_record.


#### Сокращения (shortcuts)
``DAL shortcuts``:inxx

DAL поддерживает различные упрощающие код сокращения.
В частности:
``
myrecord = db.mytable[id]
``:code

возвращает запись с заданным ``id`` если он существует. Если ``id`` не существует, то он возвращает ``None``. Вышеуказанный оператор эквивалентен

``
myrecord = db(db.mytable.id == id).select().first()
``:code


Вы можете удалить записи с помощью id:

``
del db.mytable[id]
``:code

и это эквивалентно

``
db(db.mytable.id == id).delete()
``:code

и удаляет запись с заданным ``id``, если он существует.

Примечание: Этот сокращенный синтаксис удаления на данный момент не работает, если активирован [[контроль версий #versioning]].

Вы можете вставлять записи:

``
db.mytable[0] = dict(myfield='somevalue')
``:code

Это эквивалентно

``
db.mytable.insert(myfield='somevalue')
``:code

и это создает новую запись со значениями полей, заданных в словаре с правой стороны.

Вы можете обновить записи:

``
db.mytable[id] = dict(myfield='somevalue')
``:code

что эквивалентно

``
db(db.mytable.id == id).update(myfield='somevalue')
``:code

и он обновляет существующую запись значениями поля, задаваемых через словарь на правой стороне.

#### Извлечение (Fetching ) ``Row``

Еще один удобный синтаксис выглядит следующим образом:

``
record = db.mytable(id)
record = db.mytable(db.mytable.id == id)
record = db.mytable(id, myfield='somevalue')
``:code

Очевидно, что он похож на ``db.mytable[id]``, но вышеуказанный синтаксис является более гибким и более безопасным. Прежде всего, он проверяет, является ли ``id`` целым числом (или ``str(id)`` является целым) и возвращает ``None`` в противном случае (он никогда не вызывает исключение). Он также позволяет указать несколько условий, которым запись должна удовлетворять. Если они не будут выполнены, он также возвращает ``None``.

#### Рекурсивные выборки (``select``)
``recursive selects``:inxx

Рассмотрим предыдущую таблицу person и новую таблицу "thing", ссылающуюся на "person":
``
>>> db.define_table('thing',
                    Field('name'),
                    Field('owner_id', 'reference person'))
``:code

и простую выборку из этой таблицы:
``
>>> things = db(db.thing).select()
``:code

что эквивалентно

``
>>> things = db(db.thing._id > 0).select()
``:code

где ``._id`` является ссылкой на первичный ключ таблицы. Обычно ``db.thing._id`` такой же как ``db.thing.id`` и мы будем так считать в большей части этой книги. ``_id``:inxx


Для каждой Row из things есть возможность выборки не только полей из выбранной таблицы (thing), но и из связанных таблиц (рекурсивно):
``
>>> for thing in things: print thing.name, thing.owner_id.name
``:code

Здесь выражение ``thing.owner_id.name`` требует единичного выбора из базы данных для каждой thing в перечне things и поэтому выражение неэффективно. Мы рекомендуем использовать сцепки (joins), когда это возможно, вместо рекурсивных выборок, тем не менее, это удобно и практично при доступе к отдельным записям.

Вы также можете сделать это в обратном направлении, выбирая вещи (things), на которые ссылается person:

``
person =  db.person(id)
for thing in person.thing.select(orderby=db.thing.name):
    print person.name, 'owns', thing.name
``:code

В этих последних выражениях ``person.thing`` это сокращение для

``
db(db.thing.owner_id == person.id)
``:code

т.е. Набор (Set) вещей ``thing``, на который ссылается текущая персона ``person``. Этот синтаксис ломается, если таблица ссылок содержит несколько ссылок на указанную таблицу. В этом случае нужно быть более конкретным и использовать полный запрос (Query).

[[sqltable]]
#### Сериализация ``Rows`` в представлениях

Давайте рассмотрим следующее действие, содержащее запрос
``SQLTABLE``:inxx

``
def index():
    return dict(rows = db(query).select())
``:code

Результат выборки select может отображаться в представлении со следующим синтаксисом:
``
{{extend 'layout.html'}}
<h1>Records</h1>
{{=rows}}
``:code

Что эквивалентно:
``
{{extend 'layout.html'}}
<h1>Records</h1>
{{=SQLTABLE(rows)}}
``:code

``SQLTABLE`` преобразует строки в HTML-таблицу с заголовком, содержащим имена столбцов и одну строку для каждой записи. Строки через одну помечаются классом "even" (четные) и классом "odd" (нечетные). Под капотом, строки (Rows) сначала преобразуется в SQLTABLE объект (не следует путать с классом Table), а затем сериализуются. Значения, извлеченные из базы данных форматируются с помощью валидаторов, ассоциированных с полем, а затем экранируются.

Тем не менее, возможно и иногда удобно вызывать SQLTABLE в явном виде.

Конструктор SQLTABLE принимает следующие необязательные аргументы:

- ``linkto`` лямбда-функция или действие, которое должно использоваться для ссылки на связанные поля (по умолчанию None).
Если присвоить ему строку с именем какого-либо действия, он будет генерировать ссылку на эту функцию передавая ей, как аргументы args, имя таблицы и идентификатор каждой записи (в таком порядке). Например:
``
linkto = 'pointed_function' # генерирует что-то вроде <а href="pointed_function/table_name/id_value">
``:code
Если вы хотите, чтобы была сгенерирована другая ссылка, то вы можете указать лямбда, которая получит в качестве параметров, значение идентификатора, тип объекта (например, таблицы), а также имя объекта. Например, если вы хотите получить аргументы args в обратном порядке:
``
linkto = lambda id, type, name: URL(f='pointed_function', args=[id, name])
``:code

- ``upload`` URL-адрес или действие загрузки для обеспечения загрузки закачиваемых файлов (по умолчанию None)

- ``headers`` словарь, сопоставляющий имена полей с их надписями, которые будут использоваться в качестве заголовков (по умолчанию ``{}``). Он также может быть инструкцией. В настоящее время мы поддерживаем ``headers='fieldname:capitalize'``.

- ``truncate`` количество символов для усечения длинных значений в таблице (по умолчанию 16)

- ``columns`` список имен полей, которые будут показаны в виде столбцов (в формате tablename.fieldname).
   Те, что вне списка не отображается (по умолчанию все).
   
- ``**attributes`` общие вспомогательные атрибуты, передаваемые в основном внешнему объекту TABLE.

Вот пример:
``
{{extend 'layout.html'}}
<h1>Records</h1>
{{=SQLTABLE(rows,
            headers='fieldname:capitalize',
            truncate=100,
            upload=URL('download'))
}}
``:code

``SQLFORM.grid``:inxx ``SQLFORM.smartgrid``:inxx

------
``SQLTABLE`` полезен, но бывают времена, когда требуется большего. ``SQLFORM.grid`` является расширением SQLTABLE, который создает таблицу с поисковыми функциями и пагинацией, а также возможность открывать детальные записи, создавать, редактировать и удалять записи. `` SQLFORM.smartgrid`` является дальнейшим обобщением, которое позволяет все вышесказанное, а также создает кнопки для доступа к ссылающимся записям.
------

Ниже приведен пример использования ``SQLFORM.grid``:

``
def index():
    return dict(grid=SQLFORM.grid(query))
``:code

и соответствующее представление:

``
{{extend 'layout.html'}}
{{=grid}}
``

Для работы с несколькими строками, использование ``SQLFORM.grid`` и ``SQLFORM.smartgrid`` являются более предпочтительным, чем ``SQLTABLE``, потому что они являются более мощными. Пожалуйста, смотрите главу 7.

[[orderby]] [[limitby]] [[distinct]]
#### ``orderby``, ``groupby``, ``limitby``, ``distinct``, ``having``,``orderby_on_limitby``,``left``,``cache``

Команда ``select`` принимает ряд дополнительных аргументов.

##### Аргумент orderby

Вы можете добыть записи, отсортированные по имени:

``orderby``:inxx ``groupby``:inxx ``having``:inxx
``
>>> for row in db().select(
        db.person.ALL, orderby=db.person.name):
        print row.name
Alex
Bob
Carl
``:code

Вы можете добыть записи, отсортированные по имени в обратном порядке (обратите внимание на тильду "~"):
``
>>> for row in db().select(db.person.ALL, orderby=~db.person.name):
        print row.name
Carl
Bob
Alex
``:code

Вы можете иметь добытые записи, представленные в случайном порядке:
``
>>> for row in db().select(db.person.ALL, orderby='<random>'):
        print row.name
Carl
Alex
Bob
``:code

-----
Использование ``orderby='<random>'`` не поддерживается на Google NoSQL.  Тем не менее, в этой ситуации и также во многих других, где встроенных возможностей недостаточно, может быть использован импорт:
``
import random
rows=db(...).select().sort(lambda row: random.random())
``:code
-----

Вы можете отсортировать записи по нескольким полям петем конкатенации их с "|":
``
>>> for row in db().select(db.person.ALL, orderby=db.person.name|db.person.id):
        print row.name
Carl
Bob
Alex
``:code

##### Аргументы groupby, having

Используя ``groupby`` вместе с ``orderby``, вы можете сгруппировать записи по одинаковому значению для указанного поля (это специфика конечной базы данных, и не распространяется на Google NoSQL):
``
>>> for row in db().select(db.person.ALL,
                           orderby=db.person.name,
                           groupby=db.person.name):
        print row.name
Alex
Bob
Carl
``:code

Вы можете использовать ``having`` в сочетании с ``groupby`` для группировки по условию (то есть группировка тех записей, которые удовлетворяют ``having`` условию).

``
>>> print db(query1).select(db.person.ALL, groupby=db.person.name, having=query2)
``

Обратите внимание на то, что query1 фильтрует записи, которые будут отображаться, query2 фильтрует записи, которые будут сгруппированы.

##### Аргумент distinct
``distinct``:inxx

С аргументом ``distinct=True``, вы можете указать на выбор только отдельных записей. Это имеет тот же эффект, что и группировка с использованием всех заданных полей за исключением того, что она не требует сортировки. При использовании различий (distinct), важно не выбрать ВСЕ поля, и, в частности, чтобы не выбрать "id" поле, в противном случае все записи всегда будут различными (distinct).

Вот пример:
``
>>> for row in db().select(db.person.name, distinct=True):
        print row.name
Alex
Bob
Carl
``:code

Заметить, что ``distinct`` также может быть выражением, например:
``
>>> for row in db().select(db.person.name, distinct=db.person.name):
        print row.name
Alex
Bob
Carl
``:code

##### Аргумент limitby

С аргументом limitby=(min, max), вы можете выбрать подмножество записей из offset=min, но не включая offset=max (В этом случае, первые два начинаются с нуля):

``limitby``:inxx
``
>>> for row in db().select(db.person.ALL, limitby=(0, 2)):
        print row.name
Alex
Bob
``:code

##### Аргумент orderby_on_limitby
``orderby_on_limitby``:inxx

Обратите внимание, что DAL по умолчанию неявно добавляет orderby при использовании limitby.
Это обеспечивает, чтобы один и тот же самый запрос каждый раз возвращал те же самые результаты, важно для пагинации.
Но это может привести к проблемам производительности. 
Используйте ``orderby_on_limitby = False`` для изменения (по умолчанию True). 

##### Аргумент left

Обсуждается ниже в разделе, посвященном сцепкам

##### Аргумент cache, cacheable

Пример использования, который дает значительно быстрые выборки:
``rows = db(query).select(cache=(cache.ram, 3600), cacheable=True)``:code
Смотрите обсуждение по вопросам "кэширования выборок", ниже, для понять, какие существуют компромиссы.

#### Логические операторы

Запросы могут быть объединены с помощью логического оператора И (AND )  "``&``":

``and``:inxx ``or``:inxx ``not``:inxx
``
>>> rows = db((db.person.name=='Alex') & (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
4 Alex
``:code

и логического оператора ИЛИ (OR) "``|``":
``
>>> rows = db((db.person.name == 'Alex') | (db.person.id > 3)).select()
>>> for row in rows:
        print row.id, row.name
1 Alex
``:code

Вы можете отвергнуть запрос (или подзапрос) с логическим оператором НЕ РАВНО "``!=``":
``
>>> rows = db((db.person.name != 'Alex') | (db.person.id > 3)).select()
>>> for row in rows:
        print row.id, row.name
2 Bob
3 Carl
``:code

или путем явного отрицания с унарным оператором "``~``":
``
>>> rows = db(~(db.person.name == 'Alex') | (db.person.id > 3)).select()
>>> for row in rows:
        print row.id, row.name
2 Bob
3 Carl
``:code

------
Из-за ограничений Python, связанных с перегрузкой "``and``" и "``or``" операторов, они не могут быть использованы при формировании запросов.  Вместо этого необходимо использовать бинарные операторы "``&``" и "``|``". Обратите внимание, что эти операторы (в отличие от "``and``" и "``or``") имеют более высокий приоритет, чем операторы сравнения, так что "лишние" скобки в приведенных выше примерах, являются обязательными. Аналогичным образом, унарный оператор "``~``" имеет более высокий приоритет, чем операторы сравнения, поэтому ``~``-отрицающие сравнения также должны быть в круглых скобках.
------

Кроме того, можно создавать запросы с использованием логических операторов по месту:

``
>>> query = db.person.name != 'Alex'
>>> query &= db.person.id > 3
>>> query |= db.person.name == 'John'
``

#### Методы ``count``, ``isempty``, ``delete``, ``update``

Вы можете подсчитать количество записей в наборе:

``count``:inxx ``isempty``:inxx

``
>>> print db(db.person.id > 0).count()
3
``:code

Заметить, что ``count`` принимает необязательный аргумент ``distinct``, который по умолчанию False, и его работа очень напоминает работу того же самого аргумента для ``select``. ``count``имеет также ``cache`` Аргумент, работа которого очень напоминает работу эквивалентного аргумента метода ``select``.

Иногда вам может понадобиться проверка наличия пустой таблицы. Более эффективным способом, чем подсчет, является использование метода ``isempty``:

``
>>> print db(db.person.id > 0).isempty()
False
``:code

или, что эквивалентно:

``
>>> print db(db.person).isempty()
False
``:code

Вы можете удалить записи в наборе:

``delete``:inxx
``
>>> db(db.person.id > 3).delete()
``:code

И вы можете обновить все записи в наборе посредством передачи именованных аргументов, которые соответствуют обновляемым полям:

``update``:inxx
``
>>> db(db.person.id > 3).update(name='Ken')
``:code

#### Выражения

Значение, присвоенное оператору обновления может быть выражением. Например, рассмотрим эту модель

``
>>> db.define_table('person',
                    Field('name'),
                    Field('visits', 'integer', default=0))

>>> db(db.person.name == 'Massimo').update(visits = db.person.visits + 1)
``:code

Значения, используемые в запросах также могут быть выражениями

``
>>> db.define_table('person',
                    Field('name'),
                    Field('visits', 'integer', default=0),
                    Field('clicks', 'integer', default=0))

>>> db(db.person.visits == db.person.clicks + 1).delete()
``:code

#### Выражение ``case`` ``case``:inxx

Выражение может содержать условие для случая case, например:

``
>>> db.define_table('person', Field('name'))
>>> condition = db.person.name.startswith('M')
>>> yes_or_no = condition.case('Yes', 'No')
>>> for row in db().select(db.person.name, yes_or_no):
...     print row.person.name,  row(yes_or_no)
Max Yes
John No
``:code

#### Метод ``update_record``

``update_record``:inxx
web2py также позволяет обновлять отдельную запись, которая уже находится в памяти с помощью ``update_record``

``
>>> row = db(db.person.id == 2).select().first()
>>> row.update_record(name='Curt')
``:code

Метод ``update_record`` не следует путать с методом

``
>>> row.update(name='Curt')
``:code

потому что для одной строки, метод ``update`` обновляет объект строки, но не записи базы данных, в отличии от ``update_record``.

Кроме того, можно изменить атрибуты строки (по одной за раз), а затем вызвать ``update_record()`` без аргументов для сохранения изменений:

``
>>> row = db(db.person.id > 2).select().first()
>>> row.name = 'Curt'
>>> row.update_record() # сохранение вышеуказанного изменения
``:code

Метод ``update_record`` доступен только если поле таблицы ``id`` включается в выборку select и ``cacheable`` не задано значение ``True``.

#### Вставка и обновление из словаря

Общая проблема состоит из необходимости вставки или обновления записей в таблицу, когда все параметры - имя таблицы, обновляемое поле, и значение поля, хранятся в переменных. Например: ``tablename``, ``fieldname``, и ``value``.

Вставка может быть сделана, используя следующий синтаксис:

``
db[tablename].insert(**{fieldname:value})
``:code

Обновление записи с заданным идентификатором id может быть сделано: ``_id``:inxx

``
db(db[tablename]._id == id).update(**{fieldname:value})
``:code

Обратите внимание, мы использовали ``table._id`` вместо ``table.id``. Таким образом, запрос работает даже для таблиц с полем типа "id" которое имеет имя, отличное от "id".

#### Методы ``first`` и ``last``
``first``:inxx ``last``:inxx

Возьмем Rows объект, содержащий записи:

``
>>> rows = db(query).select()
>>> first_row = rows.first()
>>> last_row = rows.last()
``:code

что эквивалентно
``
>>> first_row = rows[0] if len(rows)>0 else None
>>> last_row = rows[-1] if len(rows)>0 else None
``:code

Обратите внимание, ``first()`` и ``last()`` позволяют получить, очевидно, первую и последнюю запись, присутствующую в запросе, но это не будет означать, что эти записи будут первой или последней из вставленных записей. В случае, если вы хотите получить первую или последнюю запись из введенных в данную таблицу, то не забудьте использовать ``orderby=db.table_name.id``. Если вы забыли, то вы получите только первую и последнюю запись возвращенного ответа на ваш запрос, который оптимизатором запросов конечной базы данных зачастую составляется в случайном порядке.

#### Методы ``as_dict`` и ``as_list``
``as_list``:inxx ``as_dict``:inxx

Объект Row может быть сериализован в обычный словарь, используя метод ``as_dict()`` и объект Rows может быть сериализовать в список словарей с помощью метода ``as_list()``. Вот несколько примеров:
``
>>> rows = db(query).select()
>>> rows_list = rows.as_list()
>>> first_row_dict = rows.first().as_dict()
``:code

Эти методы удобны для передачи Rows в общие представления и/или для сохранения Rows в сессиях (так как Rows объекты сами по себе не могут быть сериализованы, поскольку содержать ссылку на открытое соединение базы данных):

``
>>> rows = db(query).select()
>>> session.rows = rows  # не допускается!
>>> session.rows = rows.as_list()  # допускается!
``:code

#### Комбинирование строк

Объекты Row могут быть скомбинированы на уровне Python. Здесь мы предполагаем:

``
>>> print rows1
person.name
Max
Tim
>>> print rows2
person.name
John
Tim
``


Вы можете сделать пересечение записей в двух наборах строк:

``
>>> rows3 = rows1 & rows2
>>> print rows3
name
Tim
``:code

Вы можете сделать объединение записей с удалением дубликатов:

``
>>> rows3 = rows1 | rows2
>>> print rows3
name
Max
Tim
John
``:code

#### Методы ``find``, ``exclude``, ``sort``
``find``:inxx ``exclude``:inxx ``sort``:inxx

Иногда вам необходимо выполнить две выборки и одна содержит подмножество предыдущей выборки. В данном случае бессмысленно получать доступ к базе данных снова. Объекты ``find``, ``exclude`` и ``sort`` позволяют манипулировать объектом Rows и генерировать другой без доступа к базе данных. Более конкретно:

- ``find`` возвращает новый набор строк, **отфильтрованный** по условию, и оставляет оригинал без изменений.

- ``exclude`` возвращает новый набор строк Rows, **отфильтрованный** по условию, и удаляет их из исходных строк Rows.

- ``sort`` возвращает новый набор строк, **отсортированный** по условию и оставляет оригинал без изменений.

Все эти методы принимают один аргумент, функцию, которая действует на каждой отдельной строке.

Вот пример использования:
``
>>> db.define_table('person', Field('name'))
>>> db.person.insert(name='John')
>>> db.person.insert(name='Max')
>>> db.person.insert(name='Alex')
>>> rows = db(db.person).select()
>>> for row in rows.find(lambda row: row.name[0]=='M'):
        print row.name
Max
>>> print len(rows)
3
>>> for row in rows.exclude(lambda row: row.name[0]=='M'):
        print row.name
Max
>>> print len(rows)
2
>>> for row in rows.sort(lambda row: row.name):
        print row.name
Alex
John
``:code

Они могут быть скомбинированы:
``
>>> rows = db(db.person).select()
>>> rows = rows.find(lambda row: 'x' in row.name
                     ).sort(lambda row: row.name)
>>> for row in rows:
        print row.name
Alex
Max
``:code

Sort принимает необязательный аргумент ``reverse=True`` с очевидным значением.

Метод ``find`` имеет необязательный аргумент limitby с тем же синтаксисом и функциональностью как и у ``метода`` select объекта Set.



### Другие методы

#### Метод ``update_or_insert``
``update_or_insert``:inxx

Иногда вам необходимо выполнить вставку, только если нет записи с теми же значениями, как и у вставляемой.
Это можно сделать с помощью

``
db.define_table('person',
                Field('name'),
                Field('birthplace'))

db.person.update_or_insert(name='John', birthplace='Chicago')
``:code

Запись будет вставлена только если нет другого пользователя по имени Джон родом из Чикаго.

Можно указать, какие значения использовать в качестве ключа, чтобы определить существование записи. Например:
``
db.person.update_or_insert(db.person.name == 'John',
                           name='John',
                           birthplace='Chicago')
``:code

и если Джон существует, то место его рождения будет обновлено, в противном случае будет создана новая запись.

Критерий отбора в приведенном выше примере это одно поле. 
Он также может быть запросом, таким как 
``
db.person.update_or_insert((db.person.name == 'John') & (db.person.birthplace == 'Chicago'),
                           name='John',
                           birthplace='Chicago',
                           pet='Rover')
``:code

#### Методы ``validate_and_insert``, ``validate_and_update``

``validate_and_insert``:inxx ``validate_and_update``:inxx

Функция

``
ret = db.mytable.validate_and_insert(field='value')
``:code

работает очень похоже

``
id = db.mytable.insert(field='value')
``:code

за исключением того, что она вызывает валидаторы для полей перед выполнением вставки и выручает, если проверка не проходит. Если проверка не проходит ошибки можно найти в ``ret.errors``. Переменная ``ret.errors`` удерживает сопоставление ключей и значений, где каждый ключ является именем поля, проверка которого не удалась, и значением ключа является результат ошибочной проверки (сильно напоминает ``form.errors``). Если она проходит, то идентификатор новой записи содержится в ``ret.id``. Имейте в виду, что обычно проверка выполняется с помощью логики обработки форм поэтому эта функция редко требуется.

По аналогии

``
ret = db(query).validate_and_update(field='value')
``:code

работает очень похоже, как

``
num = db(query).update(field='value')
``:code

за исключением того, что она вызывает валидаторы для полей перед выполнением обновления. Обратите внимание на то, что он работает только если запрос содержит одну таблицу. Количество обновленных записей можно найти в ``ret.updated`` и ошибки будут в ``ret.errors``.

#### Метод ``smart_query`` (экспериментальный)

Есть моменты, когда вам нужно разобрать запрос с использованием естественного языка, таких как

``
name contain m and age greater than 18 #(Имя содержит букву m и возраст больше 18)
``

DAL предоставляет способ для синтаксического анализа этого типа запросов:

``
search = 'name contain m and age greater than 18'
rows = db.smart_query([db.person], search).select()
``

Первым аргументом должен быть список таблиц или полей, которые должны быть разрешены в поиске. Он поднимает ``RuntimeError``, если строка поиска является недопустимой. Эта функция может быть использована для построения RESTful интерфейсов (смотри Главу 10), и она используется внутри ``SQLFORM.grid`` и ``SQLFORM.smartgrid``.

В строке поиска smartquery, поле может быть идентифицировано только с помощью fieldname и/или с помощью tablename.fieldname. Строки могут быть заключены в двойные кавычки, если они содержат пробелы.

### Вычисляемые поля
``compute``:inxx

DAL поля могут иметь ``compute`` атрибут. Это должно быть функцией (или лямбда), которая принимает объект Row и возвращает значение для поля. Когда новая запись будет модифицирована, включая методы вставки и обновлений, и если значение поля не предусмотрено, то web2py попытается вычислить на основании других значений полей с помощью функции ``compute``. Вот пример:
``
>>> db.define_table('item',
                    Field('unit_price','double'),
                    Field('quantity','integer'),
                    Field('total_price',
                          compute=lambda r: r['unit_price'] * r['quantity']))

>>> r = db.item.insert(unit_price=1.99, quantity=5)
>>> print r.total_price
9.95
``:code

Обратите внимание на то, что вычисленное значение хранится в базе данных, и оно не вычисляется по возвращению, как и в случае виртуальных полей, описание которых будет позже. Два типичных применения вычисляемых полей:
- в вики-приложениях, для хранения введенного вики-текста, обработанного как HTML, чтобы избежать повторной обработки на каждом запросе
- для поиска, чтобы вычислить нормированные значения для поля, которые будут использоваться для поиска.

Вычисляемые поля вычисляются в том порядке, в котором они определены в определении таблицы. Вычисляемое поле может ссылаться на другие предварительно определенные вычисляемые поля (новое после v 2.5.1)

### Виртуальные поля

``virtual fields``:inxx

Виртуальные поля являются такими же как и вычисляемые поля (как и в предыдущем пункте), но они отличаются от них тем, что они являются ''виртуальными'' в прямом смысле, то есть они не хранятся в базе данных, а вычисляются каждый раз, когда записи извлекаются из базы данных. Они могут быть использованы для упрощения кода пользователя без использования дополнительного хранилища, но они не могут быть использованы для поиска.

#### Новый стиль виртуальных полей

web2py обеспечивает новый и простой способ для определения виртуальных полей и ленивых (lazy) виртуальных полей. Этот раздел маркируется как экспериментальный, поскольку API могут все же немного отличаться от того, что описано здесь.

Здесь мы рассмотрим тот же пример, что и в предыдущем пункте. В частности, мы рассмотрим следующую модель:

``
>>> db.define_table('item',
                    Field('unit_price', 'double'),
                    Field('quantity', 'integer'))
``:code

Можно определить виртуальное поле ``total_price``

``
>>> db.item.total_price = \
        Field.Virtual('total_price',
                      lambda row: row.item.unit_price * row.item.quantity)
``:code

т.е. просто сказать новому поле ``total_price`` быть ``Field.Virtual``. Единственным аргументом конструктора является функция, которая принимает строку и возвращает вычисленные значения.

Виртуальное поле, определеное как описано выше, автоматически вычисляется для всех записей при выборе записи:

``
>>> for row in db(db.item).select():
        print row.total_price
``

Кроме того, можно определить метод полей, которые вычисляются по требованию, при вызове.
Например:

``
>>> db.item.discounted_total = \
        Field.Method(lambda row, discount=0.0:
                     row.item.unit_price * row.item.quantity * (1.0 - discount / 100))
``:code

В этом случае ``row.discounted_total`` является не значением, а функцией. Функция принимает те же аргументы, что и функция, переданная конструктору ``Method`` для ``row`` за исключением того, что они являются неявными (думайте что это ``self`` для объектов rows).

Ленивое поле в приведенном выше примере, позволяет вычислить общую цену для каждого элемента ``item``:

``
>>> for row in db(db.item).select(): print row.discounted_total()
``

И оно также позволяет передавать дополнительный ``discount`` процент (15%):

``
>>> for row in db(db.item).select():
        print row.discounted_total(15)
``

Виртуальные и Метод поля также могут быть определены в месте, где определена таблица:

``
>>> db.define_table('item',
                    Field('unit_price', 'double'),
                    Field('quantity', 'integer'),
                    Field.Virtual('total_price',
                                  lambda row: ...),
                    Field.Method('discounted_total',
                                 lambda row, discount=0.0: ...))
``:code


------
Имейте в виду, что виртуальные поля не имеют тех же самых атрибутов, что и другие поля (default, readable, requires, и т.д). В старых версиях web2py они не появляются в списке ``db.table.fields`` и они требуют особого подхода для отображения в SQLFORM.grid и SQLFORM.smartgrid. Смотрите обсуждение grids и виртуальных полей в главе Формы.
------

#### Старый стиль виртуальных полей

Для того чтобы определить один или несколько виртуальных полей, вы можете также определить класс контейнера, создать его экземпляр и связать его с таблицей или выборкой. Например, рассмотрим следующую таблицу:

``
>>> db.define_table('item',
                    Field('unit_price', 'double'),
                    Field('quantity', 'integer'))
``:code

Можно определить виртуальное поле ``total_price`` как
``
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.item.unit_price*self.item.quantity
>>> db.item.virtualfields.append(MyVirtualFields())
``:code

Обратите внимание на то, что каждый метод класса, который принимает один аргумент (self) является новым виртуальным полем. Аргумент ``self`` относится к каждой отдельной строке row выборки. Значения полей получаются по полному пути, как в выражении ``self.item.unit_price``. Таблица связывается с виртуальными полями путем добавления экземпляра созданного класса виртуального поля в атрибут таблицы ``virtualfields``.

Виртуальные поля также могут получить доступ к рекурсивным полям, как в
``
>>> db.define_table('item',
                    Field('unit_price', 'double'))

>>> db.define_table('order_item',
                    Field('item', 'reference item'),
                    Field('quantity', 'integer'))
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.order_item.item.unit_price * self.order_item.quantity

>>> db.order_item.virtualfields.append(MyVirtualFields())
``:code

Обратите внимание на доступ к рекурсивному полю ``self.order_item.item.unit_price``, где ``self`` это петляющая запись.

Они также могут применяться к результату СЦЕПКИ (JOIN)
``
>>> db.define_table('item',
                    Field('unit_price', 'double'))

>>> db.define_table('order_item',
                    Field('item', 'reference item'),
                    Field('quantity', 'integer'))

>>> rows = db(db.order_item.item == db.item.id).select()
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.item.unit_price * self.order_item.quantity

>>> rows.setvirtualfields(order_item=MyVirtualFields())

>>> for row in rows:
        print row.order_item.total_price
``:code

Заметьте, как в этом случае отличается синтаксис. Виртуальное поле получает доступ к обоим полям ``self.item.unit_price`` и ``self.order_item.quantity``, которые принадлежат к сцепке выборки. Виртуальное поле прикрепляется к строкам таблицы с помощью метода ``setvirtualfields`` объекта rows. Этот метод принимает произвольное число именованных аргументов и может быть использован для установки нескольких виртуальных полей, определенных в нескольких классах, и прикрепления их к нескольким таблицам:
``
>>> class MyVirtualFields1(object):
        def discounted_unit_price(self):
            return self.item.unit_price * 0.90
>>> class MyVirtualFields2(object):
        def total_price(self):
            return self.item.unit_price * self.order_item.quantity

        def discounted_total_price(self):
            return self.item.discounted_unit_price * self.order_item.quantity

>>> rows.setvirtualfields(item=MyVirtualFields1(),
                          order_item=MyVirtualFields2())

>>> for row in rows:
        print row.order_item.discounted_total_price
``:code

Виртуальные поля могут быть ''ленивыми''; все, что для них нужно сделать, так это вернуть функцию и получить доступ к ней с помощью вызова функции:
``
>>> db.define_table('item',
                    Field('unit_price', 'double'),
                    Field('quantity', 'integer'))

>>> class MyVirtualFields(object):
        def lazy_total_price(self):
            def lazy(self=self):
                return self.item.unit_price * self.item.quantity
            return lazy

>>> db.item.virtualfields.append(MyVirtualFields())

>>> for item in db(db.item).select():
        print item.lazy_total_price()
``:code

или короче, с помощью лямбда-функции:
``
>>> class MyVirtualFields(object):
        def lazy_total_price(self):
            return lambda self=self: self.item.unit_price * self.item.quantity
``:code

### Отношения один ко многим
``one to many``:inxx

Чтобы проиллюстрировать, как реализовать отношения один ко многим с помощью web2py DAL, давайте определим другую таблицу "thing", которая обращается к таблице "person", которую мы переопределяем здесь:
``
>>> db.define_table('person',
                    Field('name'),
                    format='%(name)s')

>>> db.define_table('thing',
                    Field('name'),
                    Field('owner_id', 'reference person'),
                    format='%(name)s')
``:code

Таблица "thing" имеет два поля, имя вещи и владельца вещи. Поле "owner_id" является ссылочным полем. Поле ссылочного типа может быть указано двумя эквивалентными способами:

``
Field('owner_id', 'reference person')
Field('owner_id', db.person)
``:code

Последний способ всегда преобразуется в первый способ. Они эквивалентны, за исключением случая с ленивыми таблицами, где для собственно ссылок или других типов циклических ссылок допускается только первая нотация.

Когда типом поля является другая таблица, то предполагается, что поле ссылается на другую таблицу с помощью ее id. На самом деле, вы можете напечатать фактическое значение типа и получить:

``
>>> print db.thing.owner_id.type
reference person
``:code

Теперь вставьте три вещи, две принадлежат Алекс и одна Бобу:
``
>>> db.thing.insert(name='Boat', owner_id=1)
1
>>> db.thing.insert(name='Chair', owner_id=1)
2
>>> db.thing.insert(name='Shoes', owner_id=2)
3
``:code

Вы можете сделать выборку, как если бы вы это сделали для любой другой таблицы:
``
>>> for row in db(db.thing.owner_id == 1).select():
        print row.name
Boat
Chair
``:code

Поскольку вещь (thing) содержит ссылку на человека (person), то человек может иметь много вещей, поэтому запись в таблице person в настоящее время приобретает новый атрибут thing, который является набором Set и определяет вещи этого человека. Это позволяет с легкостью циклично пройтись по всем лицам и добыть их вещи:

``referencing``:inxx
``
>>> for person in db().select(db.person.ALL):
        print person.name
        for thing in person.thing.select():
            print '    ', thing.name
Alex
     Boat
     Chair
Bob
     Shoes
Carl
``:code

#### Внутренние сцепки

Другим способом достижения подобного результата является использование сцепок, в частности, внутреннюю сцепку INNER JOIN. web2py выполняет сцепки автоматически и прозрачно, когда запрос соединяет две или более таблиц, что показано в следующем примере:

``Rows``:inxx ``inner join``:inxx ``join``:inxx
``
>>> rows = db(db.person.id == db.thing.owner_id).select()

>>> for row in rows:
        print row.person.name, 'has', row.thing.name

Alex has Boat
Alex has Chair
Bob has Shoes
``:code

Заметим, что web2py сделал сцепку, поэтому теперь строки содержат две записи, по одной из каждой таблицы, связанные друг с другом. Поскольку две записи могут иметь поля с конфликтующими именами, то вам необходимо указать таблицу, из строки которой извлекается значение поля. Это означает, что перед тем как сделать:
``
row.name
``:code

было бы логичнее указать, что это имя человека или вещи, в результате сцепки вы получаете более явное и говорящее само за себя выражение:
``
row.person.name
``:code

или:
``
row.thing.name
``:code

Существует альтернативный синтаксис для ВНУТРЕННИХ СЦЕПОК (INNER JOINS):
``
>>> rows = db(db.person).select(join=db.thing.on(db.person.id == db.thing.owner_id))

>>> for row in rows:
    print row.person.name, 'has', row.thing.name

Alex has Boat
Alex has Chair
Bob has Shoes
``:code

В то время как выход такой же, но сгенерированный SQL в обоих случаях может быть различным. Последний синтаксис устраняет возможные неоднозначности, когда одна и та же таблица сцепляется дважды и под псевдонимами:

``
>>> db.define_table('thing',
                    Field('name'),
                    Field('owner_id1', 'reference person'),
                    Field('owner_id2', 'reference person'))

>>> rows = \
        db(db.person).select(join=[db.person.with_alias('owner_id1').on(db.person.id == db.thing.owner_id1),
                                   db.person.with_alias('owner_id2').on(db.person.id == db.thing.owner_id2)])
``

Значение ``join`` может быть списком ``db.table.on(...)`` для сцепки.

#### Левосторонная внешняя сцепка

Обратите внимание на то, что Карл не появлялся в приведенном выше списке, потому что он не имеет вещей. Если вы собираетесь сделать выборку людей (независимо есть ли у них вещи или нет) и их вещей (если они имеются вообще), тогда вам необходимо выполнить ЛЕВОСТОРОННЮЮ ВНЕШНЮЮ СЦЕПКУ (LEFT OUTER JOIN). Это делается с помощью аргумента "left" в команде на выборкку. Вот пример:

``Rows``:inxx ``left outer join``:inxx ``outer join``:inxx
``
>>> rows = db().select(db.person.ALL, db.thing.ALL,
                       left=db.thing.on(db.person.id == db.thing.owner_id))

>>> for row in rows:
        print row.person.name, 'has', row.thing.name

Alex has Boat
Alex has Chair
Bob has Shoes
Carl has None
``:code

где:
``
left = db.thing.on(...)
``:code

делает запрос на левостороннюю сцепку. При этом аргумент ``db.thing.on`` это требуемое условие для сцепки (точно такое же как и использованное выше для внутренней сцепки). В случае левосторонней сцепки, необходимо явно указать какие поля выбираются.

Множественные левосторонние сцепки могут быть скомбинированы путем передачи списка или кортежа из ``db.mytable.on(...)`` в ``left`` атрибут.

#### Группировка и подсчет

При выполнении сцепки, иногда вам может захотеться сгруппировать строки в соответствии с определенными критериями и посчитать их. Например, подсчитать количество вещей, принадлежащих каждому человеку. web2py позволяет это сделать. Во-первых, вам нужен оператор подсчета. Во-вторых, вам нужно сцепить таблицу людей с таблицей вещей через владельцев. В-третьих, вы необходимо выбрать все строки (человек + вещь), сгруппировать их по людям, и посчитать их во время группировки:

``grouping``:inxx
``
>>> count = db.person.id.count()
>>> for row in db(db.person.id == db.thing.owner_id
                  ).select(db.person.name, count, groupby=db.person.name):
        print row.person.name, row[count]

Alex 2
Bob 1
``:code

Обратите внимание, что оператор ``count`` (который является встроенным) используется в качестве поля. Единственная проблема здесь в том, как получить информацию. Каждая строка содержит очевидно человека и количество, но количество (count) не является полем таблицы person и не является таблицей. Так куда же они направляются? Они направляются в объект storage, представляющий запись с ключом, равным самому выражении запроса. Метод count объекта Field имеет необязательный ``distinct`` аргумент. При установке в ``True`` он указывает, что следует учитывать только отдельные значения поля в вопросе.

### Многие ко многим
``many-to-many``:inxx

В предыдущих примерах, мы допускали вещам иметь одного владельца, но один человек может иметь много вещей. Что делать, если лодка принадлежит Алексу и Курту? Это требует отношение многие-ко-многим, и оно реализуется через промежуточную таблицу, которая связывает человека с вещью через отношения собственности.

Вот как это сделать:
``
>>> db.define_table('person',
                    Field('name'))

>>> db.define_table('thing',
                    Field('name'))

>>> db.define_table('ownership',
                    Field('person', 'reference person'),
                    Field('thing', 'reference thing'))
``:code

существующие отношения собственности теперь можно переписать в виде:
``
>>> db.ownership.insert(person=1, thing=1)  # Алекс владеет Лодкой
>>> db.ownership.insert(person=1, thing=2)  # Алекс владеет Креслом
>>> db.ownership.insert(person=2, thing=3)  # Боб владеет Обувью

``:code

Теперь вы можете добавить новое отношение, что Курт является совладельцем Лодки:

``
>>> db.ownership.insert(person=3, thing=1)  # Курт тоже владеет Лодкой

``:code

Поскольку теперь у вас есть трехпутное отношение между таблицами, то может оказаться удобным определить новый набор, на котором и выполнять операции:

``
>>> persons_and_things = db((db.person.id == db.ownership.person) &
                            (db.thing.id == db.ownership.thing))
``:code

Теперь вам будет легче выбирать всех людей и их вещи из нового набора Set:
``
>>> for row in persons_and_things.select():
        print row.person.name, row.thing.name

Alex Boat
Alex Chair
Bob Shoes
Curt Boat
``:code

Кроме того, вы можете поискать все вещи, принадлежащие Алексу:
``
>>> for row in persons_and_things(db.person.name == 'Alex').select():
        print row.thing.name

Boat
Chair
``:code

и всех владельцев Лодки:
``
>>> for row in persons_and_things(db.thing.name == 'Boat').select():
        print row.person.name

Alex
Curt
``:code

Более легкой альтернативой Многие ко Многим отношений является пометка. Пометка обсуждается в контексте ``IS_IN_DB`` валидатора. Пометка работает даже на таких движках баз данных, которые не поддерживают СЦЕПКИ вроде Google App Engine NoSQL.

### Поля типа ``list:<type>`` и метод ``contains``
``list:string``:inxx
``list:integer``:inxx
``list:reference``:inxx
``contains``:inxx
``multiple``:inxx
``tags``:inxx

web2py предоставляет следующие специальные типы полей:

``
list:string
list:integer
list:reference <table>
``:code

Они могут содержать списки строк, целых чисел и ссылок соответственно.

На Google App Engine NoSQL поле типа ``list:string`` сопоставляется с типом ``StringListProperty``, два других сопоставляются с ``ListProperty(int)``. В реляционных базах данных они сопоставляются с текстовыми полями, которые содержат список элементов, разделенных ``|``. Например ``[1,2,3]`` является сопоставлением ``|1|2|3|``.

Для списков из строк элементы экранируются, так что любой ``|`` в элементе заменяется на ``||``. Во всяком случае это внутреннее представление и является прозрачным для пользователя.

Вы можете использовать ``list:string``, например, следующим образом:

``
>>> db.define_table('product',
                    Field('name'),
                    Field('colors', 'list:string'))

>>> db.product.colors.requires=IS_IN_SET(('red', 'blue', 'green'))

>>> db.product.insert(name='Toy Car', colors=['red', 'green'])

>>> products = db(db.product.colors.contains('red')).select()

>>> for item in products:
        print item.name, item.colors

Toy Car ['red', 'green']
``:code

``list:integer`` работает таким же образом, но элементы должны быть целыми числами.

Как обычно, требования навязываются на уровне форм, а не на уровне ``insert``.

------
Для полей типа ``list:<type>`` оператор ``contains(value)`` переводит в нетривиальный запрос, который проверяет наличие списков, содержащих ``value``. Оператор ``contains`` также работает для регулярного ``string`` и ``text`` полей и он сопоставляется с ``LIKE '%value%'``.
------

Типа ``list:reference`` и оператор ``contains(value)`` особенно полезны для денормализации отношений многие-ко-многим. Вот пример:

``
>>> db.define_table('tag',
                    Field('name'),
                    format='%(name)s')

>>> db.define_table('product',
                    Field('name'),
                    Field('tags', 'list:reference tag'))

>>> a = db.tag.insert(name='red')

>>> b = db.tag.insert(name='green')

>>> c = db.tag.insert(name='blue')

>>> db.product.insert(name='Toy Car', tags=[a, b, c])

>>> products = db(db.product.tags.contains(b)).select()

>>> for item in products:
        print item.name, item.tags

Toy Car [1, 2, 3]

>>> for item in products:
        print item.name, db.product.tags.represent(item.tags)

Toy Car red, green, blue
``:code

Обратите внимание на то, что поле ``list:reference tag`` получает ограничение по умолчанию

``
requires = IS_IN_DB(db, 'tag.id', db.tag._format, multiple=True)
``:code

что производит множественный ``SELECT/OPTION`` сброс-ящик (drop-box) в формах.

Также обратите внимание, что это поле получает по умолчанию ``represent`` атрибут, который представляет собой список ссылок в виде разделенного запятыми списка отформатированных ссылок. Это используется в формах для чтения и ``SQLTABLE``.

-----
В то время как тип ``list:reference`` имеет валидатор по умолчанию и представление по умолчанию, поля типа ``list:integer`` и ``list:string`` не имеют такого. Таким образом, эти два нуждаются в ``IS_IN_SET`` или ``IS_IN_DB`` валидаторе, если вы хотите использовать их в формах.
-----


### Другие операторы

web2py имеет другие операторы, которые предоставляют API для доступа, которые эквивалентны операторам SQL.

Давайте определим еще одну таблицу "log" для хранения событий безопасности, их времени события (event_time) и серьезности (severity), где серьезность является целым числом.

``date``:inxx ``datetime``:inxx ``time``:inxx
``
>>> db.define_table('log', Field('event'),
                           Field('event_time', 'datetime'),
                           Field('severity', 'integer'))
``:code

Как и прежде, вставим несколько событий, "сканирование портов", "XSS инъекции" и "несанкционированный вход".
Ради примера, вы можете регистрировать события с тем же самым event_time, но с различными степенями серьезности (1, 2, и 3 соответственно).
``
>>> import datetime
>>> now = datetime.datetime.now()
>>> print db.log.insert(
        event='сканирование портов', event_time=now, severity=1)
1
>>> print db.log.insert(
        event='XSS инъекции', event_time=now, severity=2)
2
>>> print db.log.insert(
        event='несанкционированный вход', event_time=now, severity=3)
3
``:code

#### Методы ``like``, ``ilike``, ``regexp``, ``startswith``, ``endswith``, ``contains``, ``upper``, ``lower``

``like``:inxx ``ilike``:inxx ``startswith``:inxx ``endswith``:inxx ``regexp``:inxx
``contains``:inxx ``upper``:inxx ``lower``:inxx

Fields have a like operator that you can use to match strings:

``
>>> for row in db(db.log.event.like('port%')).select():
        print row.event
сканирование портов
``:code

Here "port%" indicates a string starting with "port". The percent sign character, "%", is a wild-card character that means "any sequence of characters".

The like operator maps to the LIKE word in ANSI-SQL. LIKE is case-sensitive in most databases, and depends on the collation of the database itself. The ``like`` method is hence case-sensitive but it can be made case-insensitive with

``
db.mytable.myfield.like('value', case_sensitive=False)
``:code


web2py also provides some shortcuts:

``
db.mytable.myfield.startswith('value')
db.mytable.myfield.endswith('value')
db.mytable.myfield.contains('value')
``:code

which are roughly equivalent respectively to

``
db.mytable.myfield.like('value%')
db.mytable.myfield.like('%value')
db.mytable.myfield.like('%value%')
``:code

Notice that ``contains`` has a special meaning for ``list:<type>`` fields and it was discussed in a previous section.

The ``contains`` method can also be passed a list of values and an optional boolean argument ``all`` to search for records that contain all values:

``
db.mytable.myfield.contains(['value1', 'value2'], all=True)
``
or any value from the list
``
db.mytable.myfield.contains(['value1', 'value2'], all=False)
``

There is a also a ``regexp`` method that works like the ``like`` method but allows regular expression syntax for the look-up expression. It is only supported by PostgreSQL, MySQL, Oracle and SQLite (with different degree of support).

The ``upper`` and ``lower`` methods allow you to convert the value of the field to upper or lower case, and you can also combine them with the like operator:

``upper``:inxx ``lower``:inxx
``
>>> for row in db(db.log.event.upper().like('PORT%')).select():
        print row.event

сканирование портов
``:code

#### ``year``, ``month``, ``day``, ``hour``, ``minutes``, ``seconds``
``hour``:inxx ``minutes``:inxx ``seconds``:inxx ``day``:inxx ``month``:inxx ``year``:inxx

The date and datetime fields have day, month and year methods. The datetime and time fields have hour, minutes and seconds methods. Вот пример:

``
>>> for row in db(db.log.event_time.year() == 2013).select():
        print row.event

сканирование портов
XSS инъекции
несанкционированный вход
``:code

#### ``belongs``

The SQL IN operator is realized via the belongs method which returns true when the field value belongs to the specified set (list or tuples):

``belongs``:inxx
``
>>> for row in db(db.log.severity.belongs((1, 2))).select():
        print row.event

сканирование портов
XSS инъекции
``:code

The DAL also allows a nested select as the argument of the belongs operator. The only caveat is that the nested select has to be a ``_select``, not a ``select``, and only one field has to be selected explicitly, the one that defines the set.

``nested select``:inxx
``
>>> bad_days = db(db.log.severity == 3)._select(db.log.event_time)

>>> for row in db(db.log.event_time.belongs(bad_days)).select():
        print row.event

сканирование портов
XSS инъекции
несанкционированный вход
``:code

In those cases where a nested select is required and the look-up field is a reference we can also use a query as argument. Например:

``
db.define_table('person', Field('name'))
db.define_table('thing',
                Field('name'),
                Field('owner_id', 'reference thing'))

db(db.thing.owner_id.belongs(db.person.name == 'Jonathan')).select()
``:code

In this case it is obvious that the next select only needs the field referenced by the ``db.thing.owner_id`` field so we do not need the more verbose ``_select`` notation.

``nested_select``:inxx

A nested select can also be used as insert/update value but in this case the syntax is different:

``
lazy = db(db.person.name == 'Jonathan').nested_select(db.person.id)

db(db.thing.id == 1).update(owner_id = lazy)
``:code

In this case ``lazy`` is a nested expression that computes the ``id`` of person "Jonathan". The two lines result in one single SQL query.

#### ``sum``, ``avg``, ``min``, ``max`` and ``len``

``sum``:inxx ``avg``:inxx ``min``:inxx ``max``:inxx
Previously, you have used the count operator to count records. Similarly, you can use the sum operator to add (sum) the values of a specific field from a group of records. As in the case of count, the result of a sum is retrieved via the store object:
``
>>> sum = db.log.severity.sum()
>>> print db().select(sum).first()[sum]
6
``:code

You can also use ``avg``, ``min``, and ``max`` to the average, minimum, and maximum value respectively for the selected records. Например:

``
>>> max = db.log.severity.max()
>>> print db().select(max).first()[max]
3
``:code

``.len()`` computes the length of a string, text or boolean fields.

Expressions can be combined to form more complex expressions. Например here we are computing the sum of the length of all the severity strings in the logs, increased of one:

``
>>> sum = (db.log.severity.len() + 1).sum()
>>> print db().select(sum).first()[sum]
``:code

#### Substrings

One can build an expression to refer to a substring. Например, we can group things whose name starts with the same three characters and select only one from each group:

``
db(db.thing).select(distinct = db.thing.name[:3])
``:code


#### Default values with ``coalesce`` and ``coalesce_zero``

There are times when you need to pull a value from database but also need a default values if the value for a record is set to NULL. In SQL there is a keyword, ``COALESCE``, for this. web2py has an equivalent ``coalesce`` method:

``
>>> db.define_table('sysuser', Field('username'), Field('fullname'))
>>> db.sysuser.insert(username='max', fullname='Max Power')
>>> db.sysuser.insert(username='tim', fullname=None)
print db(db.sysuser).select(db.sysuser.fullname.coalesce(db.sysuser.username))
"COALESCE(sysuser.fullname, sysuser.username)"
Max Power
tim
``

Other times you need to compute a mathematical expression but some fields have a value set to None while it should be zero.
``coalesce_zero`` comes to the rescue by defaulting None to zero in the query:

``
>>> db.define_table('sysuser', Field('username'), Field('points'))
>>> db.sysuser.insert(username='max', points=10)
>>> db.sysuser.insert(username='tim', points=None)
>>> print db(db.sysuser).select(db.sysuser.points.coalesce_zero().sum())
"SUM(COALESCE(sysuser.points,0))"
10
``

### Generating raw sql
``raw SQL``:inxx

Sometimes you need to generate the SQL but not execute it. This is easy to do with web2py since every command that performs database IO has an equivalent command that does not, and simply returns the SQL that would have been executed. These commands have the same names and syntax as the functional ones, but they start with an underscore:

Here is ``_insert`` ``_insert``:inxx
``
>>> print db.person._insert(name='Alex')
INSERT INTO person(name) VALUES ('Alex');
``:code

Here is ``_count`` ``_count``:inxx
``
>>> print db(db.person.name == 'Alex')._count()
SELECT count(*) FROM person WHERE person.name='Alex';
``:code

Here is ``_select`` ``_select``:inxx
``
>>> print db(db.person.name == 'Alex')._select()
SELECT person.id, person.name FROM person WHERE person.name='Alex';
``:code

Here is ``_delete`` ``_delete``:inxx
``
>>> print db(db.person.name == 'Alex')._delete()
DELETE FROM person WHERE person.name='Alex';
``:code

And finally, here is ``_update`` ``_update``:inxx
``
>>> print db(db.person.name == 'Alex')._update()
UPDATE person SET  WHERE person.name='Alex';
``:code

-----
Moreover you can always use ``db._lastsql`` to return the most recent
SQL code, whether it was executed manually using executesql or was SQL
generated by the DAL.
-----

### Exporting and importing data
``export``:inxx ``import``:inxx

#### CSV (one Table at a time)

When a Rows object is converted to a string it is automatically
serialized in CSV:

``csv``:inxx
``
>>> rows = db(db.person.id == db.thing.owner_id).select()
>>> print rows

person.id, person.name, thing.id, thing.name, thing.owner_id
1, Alex, 1, Boat, 1
1, Alex, 2, Chair, 1
2, Bob, 3, Shoes, 2
``:code

You can serialize a single table in CSV and store it in a file "test.csv":
``
>>> open('test.csv', 'wb').write(str(db(db.person.id).select()))
``:code

This is equivalent to

``
>>> rows = db(db.person.id).select()
>>> rows.export_to_csv_file(open('test.csv', 'wb'))
``:code

You can read the CSV file back with:
``
>>> db.person.import_from_csv_file(open('test.csv', 'r'))
``:code

When importing, web2py looks for the field names in the CSV header. In this example, it finds two columns: "person.id" and "person.name". It ignores the "person." prefix, and it ignores the "id" fields. Then all records are appended and assigned new ids. Both of these operations can be performed via the appadmin web interface.

#### CSV (all tables at once)

In web2py, you can backup/restore an entire database with two commands:

To export:
``
>>> db.export_to_csv_file(open('somefile.csv', 'wb'))
``:code

To import:
``
>>> db.import_from_csv_file(open('somefile.csv', 'rb'))
``:code

This mechanism can be used even if the importing database is of a different type than the exporting database. The data is stored in "somefile.csv" as a CSV file where each table starts with one line that indicates the tablename, and another line with the fieldnames:
``
TABLE tablename
field1, field2, field3, ...
``:code

Two tables are separated ``\r\n\r\n``. The file ends with the line
``
END
``:code

The file does not include uploaded files if these are not stored in the database. In any case it is easy enough to zip the "uploads" folder separately.

When importing, the new records will be appended to the database if it is not empty. In general the new imported records will not have the same record id as the original (saved) records but web2py will restore references so they are not broken, even if the id values may change.

If a table contains a field called
"uuid", this field will be used to identify duplicates.  Also, if an
imported record has the same "uuid" as an existing record, the
previous record will be updated.

#### CSV and remote database synchronization

Consider the following model:
``
db = DAL('sqlite:memory:')
db.define_table('person',
                Field('name'),
                format='%(name)s')
db.define_table('thing',
                Field('owner_id', 'reference person'),
                Field('name'),
                format='%(name)s')

if not db(db.person).count():
    id = db.person.insert(name="Massimo")
    db.thing.insert(owner_id=id, name="Chair")
``:code

Each record is identified by an ID and referenced by that ID. If you
have two copies of the database used by distinct web2py installations,
the ID is unique only within each database and not across the databases.
This is a problem when merging records from different databases.

In order to make a record uniquely identifiable across databases, they
must:
- have a unique id (UUID),
- have an event_time (to figure out which one is more recent if multiple copies),
- reference the UUID instead of the id.

This can be achieved without modifying web2py. Here is what to do:

Change the above model into:

``
db.define_table('person',
                Field('uuid', length=64, default=lambda:str(uuid.uuid4())),
                Field('modified_on', 'datetime', default=request.now),
                Field('name'),
                format='%(name)s')

db.define_table('thing',
                Field('uuid', length=64, default=lambda:str(uuid.uuid4())),
                Field('modified_on', 'datetime', default=request.now),
                Field('owner_id', length=64),
                Field('name'),
                format='%(name)s')

db.thing.owner_id.requires = IS_IN_DB(db,'person.uuid','%(name)s')

if not db(db.person.id).count():
    id = uuid.uuid4()
    db.person.insert(name="Massimo", uuid=id)
    db.thing.insert(owner_id=id, name="Chair")
``:code

-------
Notice that in the above table definitions, the default value for the two ``uuid`` fields is set to a lambda function, which returns a UUID (converted to a string). The lambda function is called once for each record inserted, ensuring that each record gets a unique UUID, even if multiple records are inserted in a single transaction.
-------

Create a controller action to export the database:

``
def export():
    s = StringIO.StringIO()
    db.export_to_csv_file(s)
    response.headers['Content-Type'] = 'text/csv'
    return s.getvalue()
``:code

Create a controller action to import a saved copy of the other database and sync records:

``
def import_and_sync():
    form = FORM(INPUT(_type='file', _name='data'), INPUT(_type='submit'))
    if form.process().accepted:
        db.import_from_csv_file(form.vars.data.file,unique=False)
        # for every table
        for table in db.tables:
            # for every uuid, delete all but the latest
            items = db(db[table]).select(db[table].id,
                                         db[table].uuid,
                                         orderby=db[table].modified_on,
                                         groupby=db[table].uuid)
            for item in items:
                db((db[table].uuid==item.uuid) &
                   (db[table].id!=item.id)).delete()
    return dict(form=form)
``:code

Optionally you should create an index manually to make the search by uuid faster.


``XML-RPC``:inxx
Alternatively, you can use XML-RPC to export/import the file.

If the records reference uploaded files, you also need to export/import the content of the uploads folder. Notice that files therein are already labeled by UUIDs so you do not need to worry about naming conflicts and references.

#### HTML and XML (one Table at a time)

``Rows objects``:inxx
Rows objects also have an ``xml`` method (like helpers) that serializes it to XML/HTML:

``HTML``:inxx

``
>>> rows = db(db.person.id > 0).select()
>>> print rows.xml()
<table>
  <thead>
    <tr>
      <th>person.id</th>
      <th>person.name</th>
      <th>thing.id</th>
      <th>thing.name</th>
      <th>thing.owner_id</th>
    </tr>
  </thead>
  <tbody>
    <tr class="even">
      <td>1</td>
      <td>Alex</td>
      <td>1</td>
      <td>Boat</td>
      <td>1</td>
    </tr>
    ...
  </tbody>
</table>
``:code

``Rows custom tags``:inxx
If you need to serialize the Rows in any other XML format with custom tags, you can easily do that using the universal TAG helper and the * notation:
``XML``:inxx

``
>>> rows = db(db.person.id > 0).select()
>>> print TAG.result(*[TAG.row(*[TAG.field(r[f], _name=f) for f in db.person.fields]) for r in rows])

<result>
  <row>
    <field name="id">1</field>
    <field name="name">Alex</field>
  </row>
  ...
</result>
``:code

#### Data representation

``export_to_csv_file``:inxx
The ``export_to_csv_file`` function accepts a keyword argument named ``represent``. When ``True`` it will use the columns ``represent`` function while exporting the data instead of the raw data.

``colnames``:inxx
The function also accepts a keyword argument named ``colnames`` that should contain a list of column names one wish to export. It defaults to all columns.

Both ``export_to_csv_file`` and ``import_from_csv_file`` accept keyword arguments that tell the csv parser the format to save/load the files:
- ``delimiter``: delimiter to separate values (default ',')
- ``quotechar``: character to use to quote string values (default to double quotes)
- ``quoting``: quote system (default ``csv.QUOTE_MINIMAL``)

Here is some example usage:
``
>>> import csv
>>> rows = db(query).select()
>>> rows.export_to_csv_file(open('/tmp/test.txt', 'w'),
                            delimiter='|',
                            quotechar='"',
                            quoting=csv.QUOTE_NONNUMERIC)
``:code

Which would render something similar to
``
"hello"|35|"this is the text description"|"2013-03-03"
``:code

For more information consult the official Python documentation ``quoteall``:cite

### Caching selects

The select method also takes a cache argument, which defaults to None. For caching purposes, it should be set to a tuple where the first element is the cache model (cache.ram, cache.disk, etc.), and the second element is the expiration time in seconds.

In the following example, you see a controller that caches a select on the previously defined db.log table. The actual select fetches data from the back-end database no more frequently than once every 60 seconds and stores the result in cache.ram. If the next call to this controller occurs in less than 60 seconds since the last database IO, it simply fetches the previous data from cache.ram.

``cache select``:inxx
``
def cache_db_select():
    logs = db().select(db.log.ALL, cache=(cache.ram, 60))
    return dict(logs=logs)
``:code

``cacheable``:inxx

The ``select`` method has an optional ``cacheable`` argument, normally set to ``False``. When ``cacheable=True`` the resulting ``Rows`` is serializable but The ``Row``s lack ``update_record`` and ``delete_record`` methods.

If you do not need these methods you can speed up selects a lot by setting the cacheable attribute:

``
rows = db(query).select(cacheable=True)
``:code

When the ``cache`` argument is set but ``cacheable=False`` (default) only the database results are cached, not the actual Rows object. When the ``cache`` argument is used in conjunction with ``cacheable=True`` the entire Rows object is cached and this results in much faster caching:

``
rows = db(query).select(cache=(cache.ram,3600),cacheable=True)
``:code

### Self-Reference and aliases

``self reference``:inxx
``alias``:inxx
It is possible to define tables with fields that refer to themselves, Вот пример:
``reference table``:inxx
``
db.define_table('person',
                Field('name'),
                Field('father_id', 'reference person'),
                Field('mother_id', 'reference person'))
``:code

Notice that the alternative notation of using a table object as field type will fail in this case, because it uses a variable ``db.person`` before it is defined:
``
db.define_table('person',
                Field('name'),
                Field('father_id', db.person),  # wrong!
                Field('mother_id', db.person))  # wrong!
``:code

In general ``db.tablename`` and ``"reference tablename"`` are equivalent field types, but the latter is the only one allowed for self.references.

``with_alias``:inxx
If the table refers to itself, then it is not possible to perform a JOIN to select a person and its parents without use of the SQL "AS" keyword. This is achieved in web2py using the ``with_alias``. Вот пример:
``
>>> Father = db.person.with_alias('father')
>>> Mother = db.person.with_alias('mother')
>>> db.person.insert(name='Massimo')
1
>>> db.person.insert(name='Claudia')
2
>>> db.person.insert(name='Marco', father_id=1, mother_id=2)
3
>>> rows = db().select(db.person.name, Father.name, Mother.name,
                       left=(Father.on(Father.id == db.person.father_id),
                             Mother.on(Mother.id == db.person.mother_id)))

>>> for row in rows:
        print row.person.name, row.father.name, row.mother.name

Massimo None None
Claudia None None
Marco Massimo Claudia
``:code

Notice that we have chosen to make a distinction between:
- "father_id": the field name used in the table "person";
- "father": the alias we want to use for the table referenced by the above field; this is communicated to the database;
- "Father": the variable used by web2py to refer to that alias.

The difference is subtle, and there is nothing wrong in using the same name for the three of them:
``
db.define_table('person',
                Field('name'),
                Field('father', 'reference person'),
                Field('mother', 'reference person'))

>>> father = db.person.with_alias('father')
>>> mother = db.person.with_alias('mother')
>>> db.person.insert(name='Massimo')
1
>>> db.person.insert(name='Claudia')
2
>>> db.person.insert(name='Marco', father=1, mother=2)
3
>>> rows = db().select(db.person.name, father.name, mother.name,
                       left=(father.on(father.id==db.person.father),
                             mother.on(mother.id==db.person.mother)))

>>> for row in rows:
        print row.person.name, row.father.name, row.mother.name

Massimo None None
Claudia None None
Marco Massimo Claudia
``:code

But it is important to have the distinction clear in order to build correct queries.

### Advanced features

#### Table inheritance
``inheritance``:inxx

It is possible to create a table that contains all the fields from another table. It is sufficient to pass the other table in place of a field to ``define_table``. Например
``
db.define_table('person', Field('name'))
db.define_table('doctor', db.person, Field('specialization'))
``:code

``dummy table``:inxx
It is also possible to define a dummy table that is not stored in a database in order to reuse it in multiple other places. Например:

``
signature = db.Table(db, 'signature',
                     Field('created_on', 'datetime', default=request.now),
                     Field('created_by', db.auth_user, default=auth.user_id),
                     Field('updated_on', 'datetime', update=request.now),
                     Field('updated_by', db.auth_user, update=auth.user_id))

db.define_table('payment', Field('amount', 'double'), signature)
``:code

This example assumes that standard web2py authentication is enabled.

Notice that if you use ``Auth`` web2py already creates one such table for you:

``
auth = Auth(db)
db.define_table('payment', Field('amount', 'double'), auth.signature)
``

When using table inheritance, if you want the inheriting table to inherit validators, be sure to define the validators of the parent table before defining the inheriting table.

#### ``filter_in`` and ``filter_out``
``filter_in``:inxx ``filter_out``:inxx

It is possible to define a filter for each field to be called before a value is inserted into the database for that field and after a value is retrieved from the database.

Imagine for example that you want to store a serializable Python data structure in a field in the json format. Here is how it could be accomplished:

``
>>> from simplejson import loads, dumps
>>> db.define_table('anyobj',
                    Field('name'),
                    Field('data', 'text'))

>>> db.anyobj.data.filter_in = lambda obj, dumps=dumps: dumps(obj)
>>> db.anyobj.data.filter_out = lambda txt, loads=loads: loads(txt)
>>> myobj = ['hello', 'world', 1, {2: 3}]
>>> id = db.anyobj.insert(name='myobjname', data=myobj)
>>> row = db.anyobj(id)
>>> row.data
['hello', 'world', 1, {2: 3}]
``:code

Another way to accomplish the same is by using a Field of type ``SQLCustomType``, as discussed later.

#### callbacks on record insert, delete and update

``_before_insert``:inxx
``_after_insert``:inxx
``_before_update``:inxx
``_after_update``:inxx
``_before_delete``:inxx
``_after_delete``:inxx

Web2py provides a mechanism to register callbacks to be called before and/or after insert, update and delete of records.

Each table stores six lists of callbacks:

``
db.mytable._before_insert
db.mytable._after_insert
db.mytable._before_update
db.mytable._after_update
db.mytable._before_delete
db.mytable._after_delete
``:code

You can register callback function by appending it the corresponding function to one of those lists. The caveat is that depending on the functionality, the callback has different signature.

This is best explained via some examples.

``
>>> db.define_table('person', Field('name'))
>>> def pprint(*args): print args
>>> db.person._before_insert.append(lambda f: pprint(f))
>>> db.person._after_insert.append(lambda f, id: pprint(f, id))
>>> db.person._before_update.append(lambda s, f: pprint(s, f))
>>> db.person._after_update.append(lambda s, f: pprint(s, f))
>>> db.person._before_delete.append(lambda s: pprint(s))
>>> db.person._after_delete.append(lambda s: pprint(s))
``:code

Here ``f`` is a dict of fields passed to insert or update, ``id`` is the id of the newly inserted record, ``s`` is the Set object used for update or delete.

``
>>> db.person.insert(name='John')
({'name': 'John'},)
({'name': 'John'}, 1)
>>> db(db.person.id==1).update(name='Tim')
(<Set (person.id = 1)>, {'name': 'Tim'})
(<Set (person.id = 1)>, {'name': 'Tim'})
>>> db(db.person.id==1).delete()
(<Set (person.id = 1)>,)
(<Set (person.id = 1)>,)
``:code

The return values of these callback should be ``None`` or ``False``. If any of the ``_before_*`` callback returns a ``True`` value it will abort the actual insert/update/delete operation.

``update_naive``:inxx

Some times a callback may need to perform an update in the same or a different table and one wants to avoid callbacks calling themselves recursively.

For this purpose there the Set objects have an ``update_naive`` method that works like ``update`` but ignores before and after callbacks.

##### Database cascades
Database schema can define relationships which trigger deletions of related records, known as cascading. The DAL is not informed when a record is deleted due to a cascade. So an ``on_delete`` trigger will not be called due a cascade-deletion. 

[[versioning]]
#### Record versioning
``_enable_record_versioning``:inxx

It is possible to ask web2py to save every copy of a record when the record is individually modified. There are different ways to do it and it can be done for all tables at once using the syntax:

``
auth.enable_record_versioning(db)
``:code

this requires Auth and it is discussed in the chapter about authentication.
It can also be done for each individual table as discussed below.

Consider the following table:

``
db.define_table('stored_item',
                Field('name'),
                Field('quantity', 'integer'),
                Field('is_active', 'boolean',
                      writable=False, readable=False, default=True))
``:code

Notice the hidden boolean field called ``is_active`` and defaulting to
True.

We can tell web2py to create a new table (in the same or a different database) and store all previous versions of each record in the table, when modified.

This is done in the following way:
``
db.stored_item._enable_record_versioning()
``:code

or in a more verbose syntax:

``
db.stored_item._enable_record_versioning(archive_db=db,
                                         archive_name='stored_item_archive',
                                         current_record='current_record',
                                         is_active='is_active')
``

The ``archive_db=db`` tells web2py to store the archive table in the same database as the ``stored_item`` table. The ``archive_name`` sets the name for the archive table. The archive table has the same fields as the original table ``stored_item`` except that unique fields are no longer unique (because it needs to store multiple versions) and has an extra field which name is specified by ``current_record`` and which is a reference to the current record in the ``stored_item`` table.

When records are deleted, they are not really deleted. A deleted record is copied in the ``stored_item_archive`` table (like when it is modified) and the ``is_active`` field is set to False. By enabling record versioning web2py sets a ``custom_filter`` on this table that hides all records in table ``stored_item`` where the ``is_active`` field is set to False. The ``is_active`` parameter in the ``_enable_record_versioning`` method allows to specify the name of the field used by the ``custom_filter`` to determine if the field was deleted or not.

``custom_filter``s are ignored by the appadmin interface.

#### Common fields and multi-tenancy
``common fields``:inxx
``multi tenancy``:inxx

``db._common_fields`` is a list of fields that should belong to all the tables. This list can also contain tables and it is understood as all fields from the table. Например occasionally you find yourself in need to add a signature to all your tables but the ```auth`` tables. In this case, after you ``db.define_tables()`` but before defining any other table, insert

``
db._common_fields.append(auth.signature)
``

One field is special: "request_tenant".
This field does not exist but you can create it and add it to any of your tables (or all of them):

``
db._common_fields.append(Field('request_tenant',
                               default=request.env.http_host,
                               writable=False))
``

For every table with a field called ``db._request_tenant``, all records for all queries are always automatically filtered by:

``
db.table.request_tenant == db.table.request_tenant.default
``:code

and for every record inserted, this field is set to the default value.
In the example above we have chosen
``
default = request.env.http_host
``
i.e. we have chose to ask our app to filter all tables in all queries with
``
db.table.request_tenant == request.env.http_host
``

This simple trick allow us to turn any application into a multi-tenant application. i.e. even if we run one instance of the app and we use one single database, if the app is accessed under two or more domains (in the example the domain name is retrieved from ``request.env.http_host``) the visitors will see different data depending on the domain. Think of running multiple web stores under different domains with one app and one database.

You can turn off multi tenancy filters using: ``ignore_common_filters``:inxx
``
rows = db(query, ignore_common_filters=True).select()
``:code

#### Common filters

A common filter is a generalization of the above multi-tenancy idea.
It provides an easy way to prevent repeating of the same query.
Consider for example the following table:

``
db.define_table('blog_post',
                Field('subject'),
                Field('post_text', 'text'),
                Field('is_public', 'boolean'),
                common_filter = lambda query: db.blog_post.is_public==True)
``

Any select, delete or update in this table, will include only public blog posts. The attribute can also be changed in controllers:

``
db.blog_post._common_filter = lambda query: db.blog_post.is_public == True
``

It serves both as a way to avoid repeating the "db.blog_post.is_public==True" phrase in each blog post search, and also as a security enhancement, that prevents you from forgetting to disallow viewing of non-public posts.

In case you actually do want items left out by the common filter (for example, allowing the admin to see non-public posts), you can either remove the filter:
``
db.blog_post._common_filter = None
``
or ignore it:
``
db(query, ignore_common_filters=True).select(...)
``

#### Custom ``Field`` types (experimental)

``SQLCustomType``:inxx

Aside for using ``filter_in`` and ``filter_out``, it is possible to define new/custom field types.
Например we consider here a field that contains binary data in compressed form:

``
from gluon.dal import SQLCustomType
import zlib

compressed = SQLCustomType(type ='text',
                           native='text',
                           encoder=(lambda x: zlib.compress(x or '')),
                           decoder=(lambda x: zlib.decompress(x)))

db.define_table('example', Field('data', type=compressed))
``:code

``SQLCustomType`` is a field type factory. Its ``type`` argument must be one of the standard web2py types. It tells web2py how to treat the field values at the web2py level. ``native`` is the type of the field as far as the database is concerned. Allowed names depend on the database engine. ``encoder`` is an optional transformation function applied when the data is stored and ``decoder`` is the optional reversed transformation function.

This feature is marked as experimental. In practice it has been in web2py for a long time and it works but it can make the code not portable, for example when the native type is database specific. It does not work on Google App Engine NoSQL.

#### Using DAL without define tables

The DAL can be used from any Python program simply by doing this:

``
from gluon import DAL, Field
db = DAL('sqlite://storage.sqlite',folder='path/to/app/databases')
``:code

i.e. import the DAL, Field, connect and specify the folder which contains the .table files (the app/databases folder).

To access the data and its attributes we still have to define all the tables we are going to access with ``db.define_tables(...)``.

If we just need access to the data but not to the web2py table attributes, we get away without re-defining the tables but simply asking web2py to read the necessary info from the metadata in the .table files:

``
from gluon import DAL, Field
db = DAL('sqlite://storage.sqlite', folder='path/to/app/databases', auto_import=True))
``:code

This allows us to access any ``db.table`` without need to re-define it.

#### PostGIS, SpatiaLite, and MS Geo (experimental)

``PostGIS``:inxx ``StatiaLite``:inxx ``Geo Extensions``:inxx
``geometry``:inxx ``geoPoint``:inxx ``geoLine``:inxx ``geoPolygon``:inxx

The DAL supports geographical APIs using PostGIS (for PostgreSQL), spatialite (for SQLite), and MSSQL and Spatial Extensions. This is a feature that was sponsored by the Sahana project and implemented by Denes Lengyel.

DAL provides geometry and geography fields types and the following functions:

``st_asgeojson``:inxx ``st_astext``:inxx ``st_contains``:inxx
``st_distance``:inxx ``st_equals``:inxx ``st_intersects``:inxx ``st_overlaps``:inxx
``st_simplify``:inxx ``st_touches``:inxx ``st_within``:inxx

``
st_asgeojson (PostGIS only)
st_astext
st_contains
st_distance
st_equals
st_intersects
st_overlaps
st_simplify (PostGIS only)
st_touches
st_within
st_x
st_y
``

Вот несколько примеров:

``
from gluon.dal import DAL, Field, geoPoint, geoLine, geoPolygon
db = DAL("mssql://user:pass@host:db")
sp = db.define_table('spatial', Field('loc', 'geometry()'))
``:code

Below we insert a point, a line, and a polygon:
``
sp.insert(loc=geoPoint(1, 1))
sp.insert(loc=geoLine((100, 100), (20, 180), (180, 180)))
sp.insert(loc=geoPolygon((0, 0), (150, 0), (150, 150), (0, 150), (0, 0)))
``:code

Notice that
``
rows = db(sp.id > 0).select()
``:code

Always returns the geometry data serialized as text.
You can also do the same more explicitly using ``st_astext()``:

``
print db(sp.id>0).select(sp.id, sp.loc.st_astext())
spatial.id,spatial.loc.STAsText()
1, "POINT (1 2)"
2, "LINESTRING (100 100, 20 180, 180 180)"
3, "POLYGON ((0 0, 150 0, 150 150, 0 150, 0 0))"
``:code

You can ask for the native representation by using ``st_asgeojson()`` (in PostGIS only):

``
print db(sp.id>0).select(sp.id, sp.loc.st_asgeojson().with_alias('loc'))
spatial.id,loc
1, [1, 2]
2, [[100, 100], [20 180], [180, 180]]
3, [[[0, 0], [150, 0], [150, 150], [0, 150], [0, 0]]]
``:code

(notice an array is a point, an array of arrays is a line, and an array of array of arrays is a polygon).

Here are example of how to use geographical functions:

``
query = sp.loc.st_intersects(geoLine((20, 120), (60, 160)))
query = sp.loc.st_overlaps(geoPolygon((1, 1), (11, 1), (11, 11), (11, 1), (1, 1)))
query = sp.loc.st_contains(geoPoint(1, 1))
print db(query).select(sp.id, sp.loc)
spatial.id, spatial.loc
3,"POLYGON ((0 0, 150 0, 150 150, 0 150, 0 0))"
``:code

Computed distances can also be retrieved as floating point numbers:

``
dist = sp.loc.st_distance(geoPoint(-1,2)).with_alias('dist')
print db(sp.id>0).select(sp.id, dist)
spatial.id, dist
1 2.0
2 140.714249456
3 1.0
``:code

#### Copy data from one db into another

Consider the situation in which you have been using the following database:

``
db = DAL('sqlite://storage.sqlite')
``

and you wish to move to another database using a different connection string:

``
db = DAL('postgres://username:password@localhost/mydb')
``

Before you switch, you want to move the data and rebuild all the metadata for the new database. We assume the new database to exist but we also assume it is empty.

Web2py provides a script that does this work for you:

``
cd web2py
python scripts/cpdb.py \\
   -f applications/app/databases \\
   -y 'sqlite://storage.sqlite' \\
   -Y 'postgres://username:password@localhost/mydb' \\
   -d ../gluon
``

After running the script you can simply switch the connection string in the model and everything should work out of the box. The new data should be there.

This script provides various command line options that allows you to move data from one application to another, move all tables or only some tables, clear the data in the tables. For more info try:

``
python scripts/cpdb.py -h
``

#### Note on new DAL and adapters

The source code of the Database Abstraction Layer was completely rewritten in 2010. While it stays backward compatible, the rewrite made it more modular and easier to extend. Here we explain the main logic.

The file "gluon/dal.py" defines, among other, the following classes.

``
ConnectionPool
BaseAdapter extends ConnectionPool
Row
DAL
Reference
Table
Expression
Field
Query
Set
Rows
``

Their use has been explained in the previous sections, except for ``BaseAdapter``. When the methods of a ``Table`` or ``Set`` object need to communicate with the database they delegate to methods of the adapter the task to generate the SQL and or the function call.

Например:

``
db.mytable.insert(myfield='myvalue')
``

calls

``
Table.insert(myfield='myvalue')
``

which delegates the adapter by returning:

``
db._adapter.insert(db.mytable, db.mytable._listify(dict(myfield='myvalue')))
``

Here ``db.mytable._listify`` converts the dict of arguments into a list of ``(field,value)`` and calls the ``insert`` method of the ``adapter``. ``db._adapter`` does more or less the following:

``
query = db._adapter._insert(db.mytable, list_of_fields)
db._adapter.execute(query)
``

where the first line builds the query and the second executes it.

``BaseAdapter`` defines the interface for all adapters.

"gluon/dal.py" at the moment of writing this book, contains the following adapters:

``
SQLiteAdapter extends BaseAdapter
JDBCSQLiteAdapter extends SQLiteAdapter
MySQLAdapter extends BaseAdapter
PostgreSQLAdapter extends BaseAdapter
JDBCPostgreSQLAdapter extends PostgreSQLAdapter
OracleAdapter extends BaseAdapter
MSSQLAdapter extends BaseAdapter
MSSQL2Adapter extends MSSQLAdapter
MSSQL3Adapter extends MSSQLAdapter
MSSQL4Adapter extends MSSQLAdapter
FireBirdAdapter extends BaseAdapter
FireBirdEmbeddedAdapter extends FireBirdAdapter
InformixAdapter extends BaseAdapter
DB2Adapter extends BaseAdapter
IngresAdapter extends BaseAdapter
IngresUnicodeAdapter extends IngresAdapter
GoogleSQLAdapter extends MySQLAdapter
NoSQLAdapter extends BaseAdapter
GoogleDatastoreAdapter extends NoSQLAdapter
CubridAdapter extends MySQLAdapter (experimental)
TeradataAdapter extends DB2Adapter (experimental)
SAPDBAdapter extends BaseAdapter (experimental)
CouchDBAdapter extends NoSQLAdapter (experimental)
IMAPAdapter extends NoSQLAdapter (experimental)
MongoDBAdapter extends NoSQLAdapter (experimental)
VerticaAdapter extends MSSQLAdapter (experimental)
SybaseAdapter extends MSSQLAdapter (experimental)
``

which override the behavior of the ``BaseAdapter``.

Each adapter has more or less this structure:

``
class MySQLAdapter(BaseAdapter):

    # specify a diver to use
    driver = globals().get('pymysql', None)

    # map web2py types into database types
    types = {
        'boolean': 'CHAR(1)',
        'string': 'VARCHAR(%(length)s)',
        'text': 'LONGTEXT',
        ...
        }

    # connect to the database using driver
    def __init__(self, db, uri, pool_size=0, folder=None, db_codec ='UTF-8',
                 credential_decoder=lambda x:x, driver_args={},
                 adapter_args={}):
        # parse uri string and store parameters in driver_args
        ...
        # define a connection function
        def connect(driver_args=driver_args):
            return self.driver.connect(**driver_args)
        # place it in the pool
        self.pool_connection(connect)
        # set optional parameters (after connection)
        self.execute('SET FOREIGN_KEY_CHECKS=1;')
        self.execute("SET sql_mode='NO_BACKSLASH_ESCAPES';")

   # override BaseAdapter methods as needed
   def lastrowid(self, table):
        self.execute('select last_insert_id();')
        return int(self.cursor.fetchone()[0])

``:code

Looking at the various adapters as example should be easy to write new ones.

When ``db`` instance is created:

``
db = DAL('mysql://...')
``

the prefix in the uri string defines the adapter. The mapping is defined in the following dictionary also in "gluon/dal.py":

``
ADAPTERS = {
    'sqlite': SQLiteAdapter,
    'spatialite': SpatiaLiteAdapter,
    'sqlite:memory': SQLiteAdapter,
    'spatialite:memory': SpatiaLiteAdapter,
    'mysql': MySQLAdapter,
    'postgres': PostgreSQLAdapter,
    'postgres:psycopg2': PostgreSQLAdapter,
    'postgres:pg8000': PostgreSQLAdapter,
    'postgres2:psycopg2': NewPostgreSQLAdapter,
    'postgres2:pg8000': NewPostgreSQLAdapter,
    'oracle': OracleAdapter,
    'mssql': MSSQLAdapter,
    'mssql2': MSSQL2Adapter,
    'mssql3': MSSQL3Adapter,
    'mssql4' : MSSQL4Adapter,
    'vertica': VerticaAdapter,
    'sybase': SybaseAdapter,
    'db2': DB2Adapter,
    'teradata': TeradataAdapter,
    'informix': InformixAdapter,
    'informix-se': InformixSEAdapter,
    'firebird': FireBirdAdapter,
    'firebird_embedded': FireBirdAdapter,
    'ingres': IngresAdapter,
    'ingresu': IngresUnicodeAdapter,
    'sapdb': SAPDBAdapter,
    'cubrid': CubridAdapter,
    'jdbc:sqlite': JDBCSQLiteAdapter,
    'jdbc:sqlite:memory': JDBCSQLiteAdapter,
    'jdbc:postgres': JDBCPostgreSQLAdapter,
    'gae': GoogleDatastoreAdapter, # discouraged, for backward compatibility
    'google:datastore': GoogleDatastoreAdapter,
    'google:datastore+ndb': GoogleDatastoreAdapter,
    'google:sql': GoogleSQLAdapter,
    'couchdb': CouchDBAdapter,
    'mongodb': MongoDBAdapter,
    'imap': IMAPAdapter
}
``:code

the uri string is then parsed in more detail by the adapter itself.

For any adapter you can replace the driver with a different one:

``
import MySQLdb as mysqldb
from gluon.dal import MySQLAdapter
MySQLAdapter.driver = mysqldb
``
i.e. ``mysqldb`` has to be ''that module'' with a .connect() method.
You can specify optional driver arguments and adapter arguments:

``
db =DAL(..., driver_args={}, adapter_args={})
``


### Gotchas

#### SQLite
SQLite does not support dropping and altering columns. That means that web2py migrations will work up to a point. If you delete a field from a table, the column will remain in the database but will be invisible to web2py. If you decide to reinstate the column, web2py will try re-create it and fail. In this case you must set ``fake_migrate=True`` so that metadata is rebuilt without attempting to add the column again. Also, for the same reason, **SQLite** is not aware of any change of column type. If you insert a number in a string field, it will be stored as string. If you later change the model and replace the type "string" with type "integer", SQLite will continue to keep the number as a string and this may cause problem when you try to extract the data.

SQLite doesn't have a boolean type. web2py internally maps booleans to a 1 character string, with 'T' and 'F' representing True and False. The DAL handles this completely; the abstraction of a true boolean value works well.
But if you are updating the SQLite table with SQL directly, be aware of the web2py implementation, and avoid using 0 and 1 values.

#### MySQL

MySQL does not support multiple ALTER TABLE within a single transaction. This means that any migration process is broken into multiple commits. If something happens that causes a failure it is possible to break a migration (the web2py metadata are no longer in sync with the actual table structure in the database). This is unfortunate but it can be prevented (migrate one table at the time) or it can be fixed a posteriori (revert the web2py model to what corresponds to the table structure in database, set ``fake_migrate=True`` and after the metadata has been rebuilt, set ``fake_migrate=False`` and migrate the table again).

#### Google SQL

Google SQL has the same problems as MySQL and more. In particular table metadata itself must be stored in the database in a table that is not migrated by web2py. This is because Google App Engine has a read-only file system. Web2py migrations in Google:SQL combined with the MySQL issue described above can result in metadata corruption. Again, this can be prevented (by migrating the table at once and then setting migrate=False so that the metadata table is not accessed any more) or it can fixed a posteriori (by accessing the database using the Google dashboard and deleting any corrupted entry from the table called ``web2py_filesystem``.

#### MSSQL (Microsoft SQL Server)
``limitby``:inxx
MSSQL < 2012 does not support the SQL OFFSET keyword. Therefore the database cannot do pagination. When doing a ``limitby=(a,b)`` web2py will fetch the first ``b`` rows and discard the first ``a``. This may result in a considerable overhead when compared with other database engines.
If you're using MSSQL >= 2005, the recommended prefix to use is ``mssql3://`` which provides a method to avoid the issue of fetching the entire non-paginated resultset. If you're on MSSQL >= 2012, use ``mssql4://`` that uses the ``OFFSET ... ROWS ... FETCH NEXT ... ROWS ONLY`` construct to support natively pagination without performance hits like other backends.
The ``mssql://`` uri also enforces (for historical reasons) the use of ``text`` columns, that are superseeded in more recent versions (from 2005 onwards) by ``varchar(max)``. ``mssql3://`` and ``mssql4://`` should be used if you don't want to face some limitations of the - officially deprecated - ``text`` columns

MSSQL has problems with circular references in tables that have ONDELETE CASCADE. This is an MSSQL bug and you work around it by setting the ondelete attribute for all reference fields to "NO ACTION". 
You can also do it once and for all before you define tables:

``
db = DAL('mssql://....')
for key in ['reference', 'reference FK']:
    db._adapter.types[key]=db._adapter.types[key].replace('%(on_delete_action)s', 'NO ACTION')
``:code

MSSQL also has problems with arguments passed to the DISTINCT keyword and therefore
 while this works,

``
db(query).select(distinct=True)
``

this does not

``
db(query).select(distinct=db.mytable.myfield)
``

#### Oracle

Oracle also does not support pagination. It does not support neither the OFFSET nor the LIMIT keywords. Web2py achieves pagination by translating a ``db(...).select(limitby=(a,b))`` into a complex three-way nested select (as suggested by official Oracle documentation). 
This works for simple select but may break for complex selects involving aliased fields and or joins.

#### Google NoSQL (Datastore)
Google NoSQL (Datastore) does not allow joins, left joins, aggregates, expression, OR involving more than one table, the ‘like’ operator searches in "text" fields. 

Transactions are limited and not provided automatically by web2py (you need to use the Google API ``run_in_transaction`` which you can look up in the Google App Engine documentation online). 

Google also limits the number of records you can retrieve in each one query (1000 at the time of writing). On the Google datastore record IDs are integer but they are not sequential. 
While on SQL the "list:string" type is mapped into a "text" type, on the Google Datastore it is mapped into a ``ListStringProperty``. Similarly "list:integer" and "list:reference" are mapped into "ListProperty". This makes searches for content inside these fields types are more efficient on Google NoSQL than on SQL databases.
